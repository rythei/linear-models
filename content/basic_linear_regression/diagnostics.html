
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>2.9. Diagnostics for linear regression &#8212; Stat 151, Linear Models</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet">
  <link href="../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="3. Generalizing linear regression" href="../generalizing_linear_regression/chheader.html" />
    <link rel="prev" title="2.8. Hypothesis testing for the Gaussian model" href="hypothesis_testing.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Stat 151, Linear Models</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../overview.html">
   Welcome to Stat 151
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Linear models
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../python_basics/chheader.html">
   1. Python 101
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../python_basics/python_basics.html">
     1.1. The Basics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../python_basics/python_numpy.html">
     1.2. Introduction to NumPy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../python_basics/python_plotting.html">
     1.3. MatPlotLib
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="chheader.html">
   2. Basics of linear regression
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="visualizing_data.html">
     2.1. Exploring and visualizing data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="simple_linear_regression.html">
     2.2. Simple linear regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="simple_linear_regression_cont.html">
     2.3. More on simple linear regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="vectors_and_matrices.html">
     2.4. Basic concepts from linear algebra: vectors and matrices
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="multiple_predictors.html">
     2.5. Linear regression with multiple predictors
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="more_least_squares.html">
     2.6. More on least squares
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="maximum_likelihood_estimation.html">
     2.7. Maximum likelihood estimation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="hypothesis_testing.html">
     2.8. Hypothesis testing for the Gaussian model
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     2.9. Diagnostics for linear regression
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../generalizing_linear_regression/chheader.html">
   3. Generalizing linear regression
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../generalizing_linear_regression/ridge_and_lasso.html">
     3.1. Regularizing regression: LASSO and Ridge
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../generalizing_linear_regression/nonlinear_regression.html">
     3.2. Fitting nonlinear functions: polynomial regression and kernel ridge regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../generalizing_linear_regression/logistic_regression.html">
     3.3. GLMs part 1: logistic regression
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../extensions_applications/chheader.html">
   4. Extensions and applications
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        <a class="dropdown-buttons"
            href="../../_sources/content/basic_linear_regression/diagnostics.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download notebook file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/content/basic_linear_regression/diagnostics.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/erichson/LinearAlgebra/master?urlpath=tree/content/basic_linear_regression/diagnostics.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#qq-plots-for-assessing-normality">
   2.9.1. QQ plots for assessing normality
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#residual-plots-for-assessing-linearity">
   2.9.2. Residual plots for assessing linearity
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Diagnostics for linear regression</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#qq-plots-for-assessing-normality">
   2.9.1. QQ plots for assessing normality
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#residual-plots-for-assessing-linearity">
   2.9.2. Residual plots for assessing linearity
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="diagnostics-for-linear-regression">
<h1><span class="section-number">2.9. </span>Diagnostics for linear regression<a class="headerlink" href="#diagnostics-for-linear-regression" title="Permalink to this headline">¶</a></h1>
<p>In the previous sections, we’ve seen that under the assumption of the Gaussian model of linear regression, we can derive a number of useful tools for performing statistical inference on our fitted model, e.g. hypothesis tests on the coefficients.</p>
<p>However, these techniques were derived under a couple critical assumptions:</p>
<ol class="simple">
<li><p>The true model is linear, i.e. there is a population parameter vector <span class="math notranslate nohighlight">\(\boldsymbol{\beta}\)</span> such that <span class="math notranslate nohighlight">\(y = \boldsymbol{x}\cdot \boldsymbol{\beta} + \varepsilon\)</span>.</p></li>
<li><p>The errors <span class="math notranslate nohighlight">\(\varepsilon\)</span> are independent and identically distributed (across observations) following a <span class="math notranslate nohighlight">\(N(0,\sigma^2)\)</span> distribution with unknown variance <span class="math notranslate nohighlight">\(\sigma^2\)</span>.</p></li>
</ol>
<p>If either of these assumptions are (significantly) violated, then the tests we developed in the previous section are meaningless. Hence it is important for us to develop methods to evaluate whether or not these assumptions (approximately) hold.</p>
<blockquote>
<div><p>We remark that in the previous paragraph, we condition our statements with words like “significantly” and “approximately”. For data gathered in the real world, the assumptions 1 and 2 will almost never hold <em>exactly</em>, but provided they appear a reasonable model for the data we have in hand, we can still hope that the statistical tests we perform provide some usefulness; see the <a class="reference external" href="https://en.wikipedia.org/wiki/All_models_are_wrong">famous quote</a> from the statistician George Box.</p>
</div></blockquote>
<div class="section" id="qq-plots-for-assessing-normality">
<h2><span class="section-number">2.9.1. </span>QQ plots for assessing normality<a class="headerlink" href="#qq-plots-for-assessing-normality" title="Permalink to this headline">¶</a></h2>
<p>One tool that is commonly used for visually evaluating whether the assumption of normal errors is approximately correct is a <em>quantile-quantile</em> (or QQ) plot. A QQ plot works by plotting the quantiles of two distributions against each other; if the distributions are similar, the quantiles should appear to lie roughly on a line. In practice, QQ plots are typically made to compare the distribution of an empirical sample against a theoretical distribution which we hope our observations approximately follow.</p>
<p>In linear regression, we typically use QQ plots to evaluate the distribution of the residuals <span class="math notranslate nohighlight">\(r_i = y_i - \hat{y}_i\)</span>, where <span class="math notranslate nohighlight">\(\hat{y}_i\)</span> is the fitted value from a regression model. If our model is correct, then the residuals should <em>approximately</em> be distributed according to a <span class="math notranslate nohighlight">\(N(0,\sigma^2)\)</span> distribution (though not exactly – can you see why?).</p>
<p>Let’s see a simple example with some simulated data where we compare the quantiles of data drawn from a standard normal distribution against the true quantiles of the standard normal. In python, QQ plots can easily be made using the <code class="docutils literal notranslate"><span class="pre">statsmodels</span></code> package. (Note that the default in the function below is to use the standard normal distribution as the theoretical distribution, so we don’t need to specify any additional arguments.)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">statsmodels.api</span> <span class="k">as</span> <span class="nn">sm</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">n</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">sample</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">qqplot</span><span class="p">(</span><span class="n">sample</span><span class="p">,</span> <span class="n">line</span><span class="o">=</span><span class="s2">&quot;45&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/diagnostics_1_0.png" src="../../_images/diagnostics_1_0.png" />
</div>
</div>
<p>As we can see in the plot, the quantiles appear to lie almost exactly on the <span class="math notranslate nohighlight">\(y=x\)</span> line, indicating that the samples seem to come from the standard normal distribution (which they do by design in this case). When applied to the residuals <span class="math notranslate nohighlight">\(r_i\)</span>, this raises an issue: we don’t actually know the variance <span class="math notranslate nohighlight">\(\sigma^2\)</span>. Let’s see what happens if we try the same plot as above, but draw samples instead from a normal distribution with a different variance.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sample</span> <span class="o">=</span> <span class="mf">0.5</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">qqplot</span><span class="p">(</span><span class="n">sample</span><span class="p">,</span> <span class="n">line</span><span class="o">=</span><span class="s2">&quot;45&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/diagnostics_3_0.png" src="../../_images/diagnostics_3_0.png" />
</div>
</div>
<p>Now the quantiles still appear to lie on a line, but not on the <span class="math notranslate nohighlight">\(y=x\)</span> line. A simple way to try and correct for this is by considering the <em>standardized</em> residuals <span class="math notranslate nohighlight">\(s_i = r_i/\hat{\sigma}\)</span>, where <span class="math notranslate nohighlight">\(\hat{\sigma}^2\)</span> is our usual estimate of the residual variance. The <code class="docutils literal notranslate"><span class="pre">qqplot</span></code> function actually has an option to do this automatically for us, by setting <code class="docutils literal notranslate"><span class="pre">fit=True</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sample</span> <span class="o">=</span> <span class="mf">0.5</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">qqplot</span><span class="p">(</span><span class="n">sample</span><span class="p">,</span> <span class="n">fit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">line</span><span class="o">=</span><span class="s2">&quot;45&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/diagnostics_5_0.png" src="../../_images/diagnostics_5_0.png" />
</div>
</div>
<p>Now our quantiles again lie roughly on the <span class="math notranslate nohighlight">\(y=x\)</span> line. The plot shown above is the one you will typically see reported as a diagnostic alongside a fitted linear regression model, though we should note that it is not quite accurate. Since we had to estimate the variance of the errors using <span class="math notranslate nohighlight">\(\hat{\sigma}\)</span>, it would really be more accurate to compare the quantiles of the standardized residuals to an appropriate <span class="math notranslate nohighlight">\(t\)</span> distribution. This can also be done using the <code class="docutils literal notranslate"><span class="pre">statsmodels</span></code> function by specifying a target distribution. For example, the following compares the quantiles of the empirically standardized normal samples against a <span class="math notranslate nohighlight">\(t\)</span> distribution with <span class="math notranslate nohighlight">\(n-1\)</span> degrees of freedom.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">scipy.stats</span> <span class="k">as</span> <span class="nn">stats</span>

<span class="n">sample</span> <span class="o">=</span> <span class="mf">0.5</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">qqplot</span><span class="p">(</span><span class="n">sample</span><span class="p">,</span> <span class="n">dist</span><span class="o">=</span><span class="n">stats</span><span class="o">.</span><span class="n">t</span><span class="p">,</span> <span class="n">distargs</span><span class="o">=</span><span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">,),</span> <span class="n">fit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">line</span><span class="o">=</span><span class="s2">&quot;45&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/diagnostics_7_0.png" src="../../_images/diagnostics_7_0.png" />
</div>
</div>
<p>While this is technically the more accurate thing to do, for <span class="math notranslate nohighlight">\(n\)</span> reasonably large the distinction is often negligible, especially since these plots are typically used only as a visual diagnostic, rather than a formal statistcal test.</p>
<p>Let’s see a few examples with an actual regression model. For this, we will use the urbanization vs GDP dataset.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;datasets/urbanization-vs-gdp-2015.csv&#39;</span><span class="p">)</span>
<span class="n">dataset</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Unnamed: 0</th>
      <th>country</th>
      <th>percent_urban_pop</th>
      <th>gdp_per_capita</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>66</td>
      <td>Afghanistan</td>
      <td>24.803</td>
      <td>1928.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>585</td>
      <td>Albania</td>
      <td>57.434</td>
      <td>10032.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>844</td>
      <td>Algeria</td>
      <td>70.848</td>
      <td>14004.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1476</td>
      <td>Angola</td>
      <td>63.446</td>
      <td>8689.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2121</td>
      <td>Argentina</td>
      <td>91.503</td>
      <td>19502.0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Recall that for this dataset, the relationship between <code class="docutils literal notranslate"><span class="pre">percent_urban_pop</span></code> (the percent of the population living in urban areas) and <code class="docutils literal notranslate"><span class="pre">gdp_per_capita</span></code> appears to be monotonic but non-linear. However, this can be corrected by applying a log transformation to <code class="docutils literal notranslate"><span class="pre">gdp_per_capita</span></code>, as demonstrated by the following scatterplots.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">axs</span> <span class="o">=</span> <span class="n">axs</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>

<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;percent_urban_pop&quot;</span><span class="p">],</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;gdp_per_capita&quot;</span><span class="p">])</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Percent Urban Pop&quot;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;GDP Per Capita&quot;</span><span class="p">)</span>

<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;percent_urban_pop&quot;</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;gdp_per_capita&quot;</span><span class="p">]))</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Percent Urban Pop&quot;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;log(GDP Per Capita)&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/diagnostics_11_0.png" src="../../_images/diagnostics_11_0.png" />
</div>
</div>
<p>Let’s fit linear regression to both the transformed and non-transformed datasets and see what the corresponding QQ plots show us. First we prep our data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ones</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">ones</span><span class="p">,</span> <span class="n">dataset</span><span class="p">[[</span><span class="s2">&quot;percent_urban_pop&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;gdp_per_capita&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="n">y_log</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Next, let’s actually fit the models and get the fitted values <span class="math notranslate nohighlight">\(\hat{y}\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">beta_hat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">X</span><span class="p">)),</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>
<span class="n">beta_hat_transformed</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">X</span><span class="p">)),</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">y_log</span><span class="p">))</span>

<span class="n">y_hat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">beta_hat</span><span class="p">)</span>
<span class="n">y_hat_transformed</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">beta_hat_transformed</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>To make the QQ plots, the last thing we need to do are compute the residuals.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">r</span> <span class="o">=</span> <span class="n">y</span><span class="o">-</span><span class="n">y_hat</span>
<span class="n">r_transformed</span> <span class="o">=</span> <span class="n">y_log</span><span class="o">-</span><span class="n">y_hat_transformed</span>
</pre></div>
</div>
</div>
</div>
<p>Now we can make QQ plots for these two models.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">axs</span> <span class="o">=</span> <span class="n">axs</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">qqplot</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">fit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">line</span><span class="o">=</span><span class="s2">&quot;45&quot;</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Untransformed model&quot;</span><span class="p">)</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">qqplot</span><span class="p">(</span><span class="n">r_transformed</span><span class="p">,</span> <span class="n">fit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">line</span><span class="o">=</span><span class="s2">&quot;45&quot;</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Log-transformed model&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/diagnostics_19_0.png" src="../../_images/diagnostics_19_0.png" />
</div>
</div>
<p>From these plots we can see that the errors from the untransformed model do not appear to follow a normal distribution at all, as the residual quantiles vs the normal quantiles do not lie close to the <span class="math notranslate nohighlight">\(y=x\)</span> line. On the other hand, for the log-transformed model the residuals look much better, closely matching the <span class="math notranslate nohighlight">\(y=x\)</span> line. For the latter case, we may be confident that our assumption of normal errors (at least approximately) holds, and that we can apply our statistical tools to perform inference on such a model.</p>
<p>Before moving on to other diagnostic tools, let’s inspect the non-transformed model a bit more closely. Note that the QQ plot here exhibits a “bent upward” trend; this corresponds to residuals which are skewed to the right. We can verify this by looking at a histogram of the residuals themselves:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Residuals&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/diagnostics_21_0.png" src="../../_images/diagnostics_21_0.png" />
</div>
</div>
<p>Skewed residuals like this occur when a few observations have large positive deviations, i.e. the true <span class="math notranslate nohighlight">\(y\)</span> value is much larger than the predicted <span class="math notranslate nohighlight">\(\hat{y}\)</span>. Can you think of why this might occcur for the GDP per capita data?</p>
</div>
<div class="section" id="residual-plots-for-assessing-linearity">
<h2><span class="section-number">2.9.2. </span>Residual plots for assessing linearity<a class="headerlink" href="#residual-plots-for-assessing-linearity" title="Permalink to this headline">¶</a></h2>
<p>In addition to QQ plots, there are a number of other visual diagnostics that are often inspected after performing a regression analysis. Here, we will discuss one of these: namely a plot of the residuals verses the fitted values of the regression model.</p>
<p>Linearity is of course one of the key assumptions of fitting a linear regression model, i.e. that the observed data is generated by some (unknown) linear model of the form <span class="math notranslate nohighlight">\(y_i = \boldsymbol{\beta} \cdot \boldsymbol{x}_i+\varepsilon_i\)</span>. One way to check this assumption is by creating a plot of the residuals <span class="math notranslate nohighlight">\(r_i = y_i - \hat{y}_i\)</span> versus the fitted values <span class="math notranslate nohighlight">\(\hat{y}_i\)</span>. If our assumption of linearity is correct, the this plot should look like points scattered around zero regardless of the value of <span class="math notranslate nohighlight">\(\hat{y}_i\)</span>. On the other hand, if this assumption is violated, then we should observe distinct deviations from zero that occur as a function of <span class="math notranslate nohighlight">\(\hat{y}_i\)</span>.</p>
<p>Let’s use the two example models above for GDP per capita and urban population as an example to compute these plots.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">axs</span> <span class="o">=</span> <span class="n">axs</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>

<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">r</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">hlines</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">y_hat</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">y_hat</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Fitted Values&quot;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Residuals&quot;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Untransformed model&quot;</span><span class="p">)</span>

<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">y_hat_transformed</span><span class="p">,</span> <span class="n">r_transformed</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">hlines</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">y_hat_transformed</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">y_hat_transformed</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Fitted Values&quot;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Residuals&quot;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Log-transformed model&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/diagnostics_23_0.png" src="../../_images/diagnostics_23_0.png" />
</div>
</div>
<p>The second plot (for the log-transformed models), perhaps unsurprisingly, looks good – exactly what we’d expect if the true model is actually linear. Let us discuss the first plot, for the untransformed model, a bit more. Notice that for small value of <span class="math notranslate nohighlight">\(\hat{y}\)</span>, the residuals are almost exclusively positive, meaning that the model under-predicts for small values of <span class="math notranslate nohighlight">\(y\)</span>. If the true model were linear (with mean zero errors), we wouldn’t expect this type of behavior.</p>
<blockquote>
<div><p>We remark that this plot is perhaps superfluous for the simple linear regression setting (with one predictor), since we could simply plot GDP per capita against percent urban population and see directly that the relationship between the two is not linear. However, as soon as we have more predictors, this becomes impossible. The benefit of using a residual vs predicted value plot is that it works <em>regardless of how many predictors we have</em>.</p>
</div></blockquote>
<p>Note that it would also be perfectly reasonable to instead plot the observed values <span class="math notranslate nohighlight">\(y_i\)</span> against the fitted <span class="math notranslate nohighlight">\(\hat{y}_i\)</span>’s; this would largely convey the same information as the residual vs fitted values plot. In this case, we would want the points to lie roughly on the <span class="math notranslate nohighlight">\(y=x\)</span> line. However, it is standard practice to instead substract out the fitted values on the <span class="math notranslate nohighlight">\(y\)</span>-axis so that the points should lie around zero. For completeness, we show what this would look like in the following plots.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">axs</span> <span class="o">=</span> <span class="n">axs</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>

<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">y_hat</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">y</span><span class="p">)],</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">y_hat</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">y</span><span class="p">)],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Fitted Values&quot;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Observed Values&quot;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Untransformed model&quot;</span><span class="p">)</span>

<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">y_hat_transformed</span><span class="p">,</span> <span class="n">y_log</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">y_hat_transformed</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">y_log</span><span class="p">)],</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">y_hat_transformed</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">y_log</span><span class="p">)],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Fitted Values&quot;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Observed Values&quot;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Log-transformed model&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/diagnostics_25_0.png" src="../../_images/diagnostics_25_0.png" />
</div>
</div>
<p>There are many other plots and diagnostics that are used to evaluate linear regression models; for example, a scale-location plot can be used to check whether the errors have the same variance across observations. In the homework, we will discuss concept called <em>leverage</em>, which is also an important tool for identifying outlier that significantly affect a regression model.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./content/basic_linear_regression"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="hypothesis_testing.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">2.8. </span>Hypothesis testing for the Gaussian model</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="../generalizing_linear_regression/chheader.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">3. </span>Generalizing linear regression</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Michael W. Mahoney and Ryan Theisen<br/>
    
        &copy; Copyright 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>