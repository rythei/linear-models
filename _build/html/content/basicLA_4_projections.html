
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>6.4. Projections &#8212; Linear Algebra for Data Workbook</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="7. Eigenthings" href="eigenstuff_chheader.html" />
    <link rel="prev" title="6.3. Solving linear systems with the QR decomposition" href="basicLA_4_QR_linear_systems.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Linear Algebra for Data Workbook</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../overview.html">
   Welcome to Stat 89A
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Background
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="python_chheader.html">
   1. Python 101
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="python_basics.html">
     1.1. The Basics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="python_numpy.html">
     1.2. Introduction to NumPy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="python_plotting.html">
     1.3. MatPlotLib
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Basic Linear Algebra
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="basicLA_1_chheader.html">
   2. Matrices, vectors, and
   <span class="math notranslate nohighlight">
    \(\mathbb{R}^n\)
   </span>
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="basicLA_1_introduction-to-norms.html">
     2.1. Introduction to Norms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="basicLA_1_norms-integration-monte-carlo.html">
     2.2. An application: approximating integrals with norms and Monte Carlo integration
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="basicLA_1_lp-balls.html">
     2.3.
     <span class="math notranslate nohighlight">
      \(\ell_p\)
     </span>
     Balls
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="basicLA_1_classification-with-norms.html">
     2.4. An application: classifying data points using norms
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="basicLA_2_chheader.html">
   3. Basics of vectors and vector spaces
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="basicLA_2A_vectorspaces.html">
     3.1. Vectors and vector spaces
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="basicLA_3_chheader.html">
   4. Basics of matrices
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="basicLA_3_matrices-and-matrix-operations.html">
     4.1. Matrices and matrix operations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="basicLA_3_deconstructing.html">
     4.2. Deconstructing Matrix Multiplication
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="basicLA_3_powers_of_matrices.html">
     4.3. Taking Powers of Matrices
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="basicLA_3B_chheader.html">
   5. Matrices as transformations
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="basicLA_3_linear_examples_new.html">
     5.1. Linear and Nonlinear Functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="basicLA_3_matrices_and_linear_functions.html">
     5.2. Matrices and Linear Functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="basicLA_3_injective-and-surjective-functions.html">
     5.3. Injective, surjective and invertible functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="basicLA_3_inverses.html">
     5.4. Left Inverses, Right Inverses, and Inverses
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="basicLA_3_changing_basis.html">
     5.5. Changing Basis
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="basicLA_4_chheader.html">
   6. Geometry: angles, orthogonality, and projections
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="basicLA_4_dot-products-and-angles.html">
     6.1. Dot products, angles, and orthogonality
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="basicLA_4_QR.html">
     6.2. Gram–Schmidt and the QR Decomposition
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="basicLA_4_QR_linear_systems.html">
     6.3. Solving linear systems with the QR decomposition
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     6.4. Projections
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  The EVD, SVD and applications
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="eigenstuff_chheader.html">
   7. Eigenthings
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="eigenstuff_quadratic-forms.html">
     7.1. Quadratic forms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="eigenstuff_eigenthings.html">
     7.2. Eigenvalues and eigenvectors
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="eigenstuff_eigenthings-special-matrices.html">
     7.3. The Eigenvalue decomposition for special types of matrices
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="eigenstuff_qr-algorithm.html">
     7.4. The QR algorithm for finding eigenvalues and eigenvectors
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="eigenstuff_SVD.html">
     7.5. The Singular Value Decomposition
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="eigenstuff_low-rank-approximation.html">
     7.6. Low-rank approximation using the SVD
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="applications_chheader.html">
   8. Applications
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="applications_PCA.html">
     8.1. Principal Component Analysis (PCA)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="applications_spectral-clustering.html">
     8.2. Sprectral Clustering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="applications_least-squares.html">
     8.3. Least Squares
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="applications_double-descent.html">
     8.4. The “double descent” phenomenon
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        <a class="dropdown-buttons"
            href="../_sources/content/basicLA_4_projections.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download notebook file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/content/basicLA_4_projections.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/erichson/LinearAlgebra/master?urlpath=tree/content/basicLA_4_projections.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#projections-onto-a-vector">
   6.4.1. Projections onto a vector
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#orthogonal-projections-onto-a-vector">
     6.4.1.1. Orthogonal projections onto a vector
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#oblique-projections-onto-a-vector">
     6.4.1.2. Oblique projections onto a vector
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#projections-onto-a-subspace">
   6.4.2. Projections onto a subspace
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#orthogonal-projections-onto-a-subspace">
     6.4.2.1. Orthogonal projections onto a subspace
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#relationship-with-the-qr-decomposition">
       6.4.2.1.1. Relationship with the QR decomposition
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#oblique-projections-onto-a-subspace">
     6.4.2.2. Oblique projections onto a subspace
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#projecting-onto-the-orthogonal-complement-of-a-subspace">
   6.4.3. Projecting onto the orthogonal complement of a subspace
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Projections</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#projections-onto-a-vector">
   6.4.1. Projections onto a vector
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#orthogonal-projections-onto-a-vector">
     6.4.1.1. Orthogonal projections onto a vector
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#oblique-projections-onto-a-vector">
     6.4.1.2. Oblique projections onto a vector
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#projections-onto-a-subspace">
   6.4.2. Projections onto a subspace
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#orthogonal-projections-onto-a-subspace">
     6.4.2.1. Orthogonal projections onto a subspace
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#relationship-with-the-qr-decomposition">
       6.4.2.1.1. Relationship with the QR decomposition
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#oblique-projections-onto-a-subspace">
     6.4.2.2. Oblique projections onto a subspace
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#projecting-onto-the-orthogonal-complement-of-a-subspace">
   6.4.3. Projecting onto the orthogonal complement of a subspace
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="projections">
<h1><span class="section-number">6.4. </span>Projections<a class="headerlink" href="#projections" title="Permalink to this headline">¶</a></h1>
<p>In this section, we study special linear maps called <em>projections</em>. Formally, a projection <span class="math notranslate nohighlight">\(P(\boldsymbol{x})\)</span> is any linear map such that <span class="math notranslate nohighlight">\(P^2 = P\)</span>. In other words, a projection is simply a <em>idemptotent</em> linear map.</p>
<div class="section" id="projections-onto-a-vector">
<h2><span class="section-number">6.4.1. </span>Projections onto a vector<a class="headerlink" href="#projections-onto-a-vector" title="Permalink to this headline">¶</a></h2>
<p>We begin by considering perhaps the simplest possible projection: a projection onto a single vector. Intuitively, this is probably something you’ve already seen in high school math. The usual diagram given for this concept is below.</p>
<img src="img/projection_2d.png" style="zoom:50%;" />
<p>In the above figure, we are projecting a vector <span class="math notranslate nohighlight">\(\boldsymbol{a}\)</span> onto a vector <span class="math notranslate nohighlight">\(\boldsymbol{b}\)</span>. The resulting projection is the vector <span class="math notranslate nohighlight">\(\text{proj}_\boldsymbol{b}(\boldsymbol{a}) = \boldsymbol{a}_1\)</span>, which is always parallel to <span class="math notranslate nohighlight">\(\boldsymbol{b}\)</span>. The vector <span class="math notranslate nohighlight">\(\boldsymbol{a}_2\)</span> is the “residual” of the projection, which is  <span class="math notranslate nohighlight">\(\boldsymbol{a}_2 = \boldsymbol{a} - \boldsymbol{a}_1 = \boldsymbol{a} - \text{proj}_\boldsymbol{b}(\boldsymbol{a})\)</span>. Note that visually from the diagram, we have that <span class="math notranslate nohighlight">\(\boldsymbol{a} = \boldsymbol{a}_1 + \boldsymbol{a}_2\)</span>, which is of course obvious from the definitions of <span class="math notranslate nohighlight">\(\boldsymbol{a}_1\)</span> and <span class="math notranslate nohighlight">\(\boldsymbol{a}_2\)</span>. We will see below that this diagram is in fact representing a special case of projection onto a vector – namely, it represents an <em>orthogonal</em> projection.</p>
<div class="section" id="orthogonal-projections-onto-a-vector">
<h3><span class="section-number">6.4.1.1. </span>Orthogonal projections onto a vector<a class="headerlink" href="#orthogonal-projections-onto-a-vector" title="Permalink to this headline">¶</a></h3>
<p>There is a simple formula for the orthogonal projection of a vector <span class="math notranslate nohighlight">\(\boldsymbol{a} \in\mathbb{R}^n\)</span> onto another vector <span class="math notranslate nohighlight">\(\boldsymbol{b}\in \mathbb{R}^n\)</span>. It is given by the following:</p>
<div class="math notranslate nohighlight">
\[
\text{proj}_\boldsymbol{b}(\boldsymbol{a}) = \frac{\boldsymbol{b}^\top \boldsymbol{a}}{\boldsymbol{b}^\top \boldsymbol{b}}\boldsymbol{b}
\]</div>
<p>Notice that <span class="math notranslate nohighlight">\(\frac{\boldsymbol{b}^\top \boldsymbol{a}}{\boldsymbol{b}^\top \boldsymbol{b}}\)</span> is just a scalar (assuming <span class="math notranslate nohighlight">\(\boldsymbol{b}\neq 0\)</span>), and so <span class="math notranslate nohighlight">\(\text{proj}_\boldsymbol{b}(\boldsymbol{a})\)</span> is really just a rescaled version of the vector <span class="math notranslate nohighlight">\(\boldsymbol{b}\)</span>. This means that for any vector <span class="math notranslate nohighlight">\(\boldsymbol{a}\)</span>, <span class="math notranslate nohighlight">\(\text{proj}_\boldsymbol{b}(\boldsymbol{a})\)</span> is always parallel to <span class="math notranslate nohighlight">\(\boldsymbol{b}\)</span> – this is why we say that it is a projection “onto” <span class="math notranslate nohighlight">\(\boldsymbol{b}\)</span>. Why is this called an ‘orthogonal’ projection? This is because <span class="math notranslate nohighlight">\(\text{proj}_\boldsymbol{b}(\boldsymbol{a})\)</span> is always orthogonal to the “residual” <span class="math notranslate nohighlight">\(\boldsymbol{a} - \text{proj}_\boldsymbol{b}(\boldsymbol{a})\)</span>. Let’s check that this is in fact true by computing <span class="math notranslate nohighlight">\(\text{proj}_\boldsymbol{b}(\boldsymbol{a})^\top (\boldsymbol{a} - \text{proj}_\boldsymbol{b}(\boldsymbol{a}))\)</span>.</p>
<div class="math notranslate nohighlight">
\[
\text{proj}_\boldsymbol{b}(\boldsymbol{a})^\top (\boldsymbol{a} - \text{proj}_\boldsymbol{b}(\boldsymbol{a})) = \left(\frac{\boldsymbol{b}^\top \boldsymbol{a}}{\boldsymbol{b}^\top \boldsymbol{b}}\boldsymbol{b}\right)^\top\left(\boldsymbol{a} - \frac{\boldsymbol{b}^\top \boldsymbol{a}}{\boldsymbol{b}^\top \boldsymbol{b}}\boldsymbol{b}\right) = \frac{\boldsymbol{b}^\top \boldsymbol{a}}{\boldsymbol{b}^\top \boldsymbol{b}}\left(\boldsymbol{b}^\top \boldsymbol{a} - \boldsymbol{b}^\top \boldsymbol{a}\frac{\boldsymbol{b}^\top \boldsymbol{b}}{\boldsymbol{b}^\top \boldsymbol{b}}\right) = \frac{\boldsymbol{b}^\top \boldsymbol{a}}{\boldsymbol{b}^\top \boldsymbol{b}}(\boldsymbol{b}^\top \boldsymbol{a} - \boldsymbol{b}^\top \boldsymbol{a}) = 0
\]</div>
<p>Hence the angle between <span class="math notranslate nohighlight">\(\text{proj}_\boldsymbol{b}(\boldsymbol{a})\)</span> and <span class="math notranslate nohighlight">\(\boldsymbol{a} - \text{proj}_\boldsymbol{b}(\boldsymbol{a})\)</span> is always <span class="math notranslate nohighlight">\(90^\circ\)</span>. You can also see this visually in the figure above.</p>
<p><strong>Remark:</strong> In the QR decomposition section, we saw the formula <span class="math notranslate nohighlight">\(\frac{\boldsymbol{b}^\top \boldsymbol{a}}{\boldsymbol{b}^\top \boldsymbol{b}}\boldsymbol{b}\)</span> appear in the Gram–Schmidt orthogonalization procedure. This is no coincidence: there, we computed</p>
<div class="math notranslate nohighlight">
\[
\boldsymbol{u}_j = \boldsymbol{a}_j - \sum_{i = 1}^{j-1}\frac{\boldsymbol{u}_i^\top \boldsymbol{a}_j}{\boldsymbol{u}_i^\top \boldsymbol{u}_i}\boldsymbol{u}_i = \boldsymbol{a}_j - \sum_{i=1}^{j-1}\text{proj}_{\boldsymbol{u}_i}(\boldsymbol{a}_j)
\]</div>
<p>That is, <span class="math notranslate nohighlight">\(\boldsymbol{u}_j\)</span> was the residual after projecting <span class="math notranslate nohighlight">\(\boldsymbol{a}_j\)</span> onto each of <span class="math notranslate nohighlight">\(\boldsymbol{u}_1,\dots, \boldsymbol{u}_{j-1}\)</span>.</p>
<p>As we mentioned previously, the projections we consider are <em>linear</em> maps. We know that all linear maps can be represented as matrices. Let’s see how we can represent <span class="math notranslate nohighlight">\(\text{proj}_\boldsymbol{b}(\boldsymbol{a})\)</span> as a matrix transformation. Using the associativity of inner and outer products, we can rearrange the formula for <span class="math notranslate nohighlight">\(\text{proj}_\boldsymbol{b}\)</span> to see</p>
<div class="math notranslate nohighlight">
\[
\text{proj}_\boldsymbol{b}(\boldsymbol{a}) = \frac{\boldsymbol{b}^\top \boldsymbol{a}}{\boldsymbol{b}^\top \boldsymbol{b}}\boldsymbol{b} = \frac{1}{\boldsymbol{b}^\top \boldsymbol{b}}\boldsymbol{b}\boldsymbol{b}^\top \boldsymbol{a} = \frac{\boldsymbol{b}\boldsymbol{b}^\top}{\boldsymbol{b}^\top \boldsymbol{b}}\boldsymbol{a} = \boldsymbol{P_ba}
\]</div>
<p>where <span class="math notranslate nohighlight">\(\boldsymbol{P_b} = \frac{\boldsymbol{bb}^\top}{\boldsymbol{b}^\top \boldsymbol{b}}\)</span> is an <span class="math notranslate nohighlight">\(n\times n\)</span> matrix.</p>
<p>As we mentioned before, projections should by definition satisfy the idempotence property <span class="math notranslate nohighlight">\(\boldsymbol{P}^2 = \boldsymbol{P}\)</span>. Let’s check that this is true for <span class="math notranslate nohighlight">\(\boldsymbol{P_b}\)</span>. We have</p>
<div class="math notranslate nohighlight">
\[
\boldsymbol{P_b}^2 = \frac{\boldsymbol{bb}^\top}{\boldsymbol{b}^\top \boldsymbol{b}}\frac{\boldsymbol{bb}^\top}{\boldsymbol{b}^\top \boldsymbol{b}} = \frac{1}{(\boldsymbol{b}^\top \boldsymbol{b})^2}\boldsymbol{bb}^\top \boldsymbol{bb}^\top = \frac{1}{(\boldsymbol{b}^\top \boldsymbol{b})^2}\boldsymbol{b}(\boldsymbol{b}^\top \boldsymbol{b})\boldsymbol{b}^\top=\frac{\boldsymbol{b}^\top \boldsymbol{b}}{(\boldsymbol{b}^\top \boldsymbol{b})^2}\boldsymbol{bb}^\top = \frac{\boldsymbol{bb}^\top}{\boldsymbol{b}^\top \boldsymbol{b}} = \boldsymbol{P_b}
\]</div>
<p>Indeed, <span class="math notranslate nohighlight">\(\boldsymbol{P_b}\)</span> is idempotent.</p>
<p>Let’s look at some <span class="math notranslate nohighlight">\(2\)</span>-d examples of orthogonal projections. First, let’s define a function <code class="docutils literal notranslate"><span class="pre">orthogonal_projection(b)</span></code> which takes in a vector <span class="math notranslate nohighlight">\(\boldsymbol{b}\)</span> and returns the projection matrix <span class="math notranslate nohighlight">\(\boldsymbol{P_b} = \frac{\boldsymbol{bb}^\top}{\boldsymbol{b}^\top \boldsymbol{b}}\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">def</span> <span class="nf">orthogonal_projection</span><span class="p">(</span><span class="n">b</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">b</span><span class="p">,</span><span class="n">b</span><span class="p">)</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">b</span><span class="p">,</span><span class="n">b</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Now let’s test this out with a vector that we’d like to project onto, say <span class="math notranslate nohighlight">\(\boldsymbol{b}=\begin{bmatrix}1\\2\end{bmatrix}\)</span>. Let’s visualize <span class="math notranslate nohighlight">\(\boldsymbol{b}\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>
<span class="n">origin</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">quiver</span><span class="p">(</span><span class="o">*</span><span class="n">origin</span><span class="p">,</span> <span class="o">*</span><span class="n">b</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">units</span><span class="o">=</span><span class="s1">&#39;xy&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mf">1.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mf">2.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">set_aspect</span><span class="p">(</span><span class="s1">&#39;equal&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/basicLA_4_projections_3_0.png" src="../_images/basicLA_4_projections_3_0.png" />
</div>
</div>
<p>Next, let’s compute the projection matrix <span class="math notranslate nohighlight">\(\boldsymbol{P_b}\)</span> using the function we defined above.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Pb</span> <span class="o">=</span> <span class="n">orthogonal_projection</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Just to make sure we’ve done things correctly, let’s verify that <span class="math notranslate nohighlight">\(\boldsymbol{P_b}\)</span> is idempotent, by checking that <span class="math notranslate nohighlight">\(\boldsymbol{P_b}^2 = \boldsymbol{P_b}\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Pb2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Pb</span><span class="p">,</span> <span class="n">Pb</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">Pb2</span><span class="p">,</span> <span class="n">Pb</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>True
</pre></div>
</div>
</div>
</div>
<p>Indeed it is. Now, let’s try projecting a vector, say <span class="math notranslate nohighlight">\(\boldsymbol{a} = \begin{bmatrix}1\\ 1\end{bmatrix}\)</span>, onto <span class="math notranslate nohighlight">\(\boldsymbol{b}\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">proj_b_a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Pb</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span> <span class="c1"># compute the projection of a onto b</span>
<span class="n">residual</span> <span class="o">=</span> <span class="n">a</span> <span class="o">-</span> <span class="n">proj_b_a</span>

<span class="n">plt</span><span class="o">.</span><span class="n">quiver</span><span class="p">(</span><span class="o">*</span><span class="n">origin</span><span class="p">,</span> <span class="o">*</span><span class="n">b</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">units</span><span class="o">=</span><span class="s1">&#39;xy&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">quiver</span><span class="p">(</span><span class="o">*</span><span class="n">origin</span><span class="p">,</span> <span class="o">*</span><span class="n">a</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">units</span><span class="o">=</span><span class="s1">&#39;xy&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">quiver</span><span class="p">(</span><span class="o">*</span><span class="n">origin</span><span class="p">,</span> <span class="o">*</span><span class="n">proj_b_a</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;proj_b(a)&#39;</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">units</span><span class="o">=</span><span class="s1">&#39;xy&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">quiver</span><span class="p">(</span><span class="o">*</span><span class="n">proj_b_a</span><span class="p">,</span> <span class="o">*</span><span class="n">residual</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;a - proj_b(a)&#39;</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">units</span><span class="o">=</span><span class="s1">&#39;xy&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;orange&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mf">1.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mf">2.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">set_aspect</span><span class="p">(</span><span class="s1">&#39;equal&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper left&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/basicLA_4_projections_9_0.png" src="../_images/basicLA_4_projections_9_0.png" />
</div>
</div>
<p>This plot now largely replicates the figure we saw earlier: we see that 1) the projection of <span class="math notranslate nohighlight">\(\boldsymbol{a}\)</span> onto <span class="math notranslate nohighlight">\(\boldsymbol{b}\)</span> is a vector (in red) which is parallel to <span class="math notranslate nohighlight">\(\boldsymbol{b}\)</span> and 2) the residual <span class="math notranslate nohighlight">\(\boldsymbol{a} - \text{proj}_\boldsymbol{b}(\boldsymbol{a})\)</span> is at a <span class="math notranslate nohighlight">\(90^\circ\)</span> angle from <span class="math notranslate nohighlight">\(\text{proj}_\boldsymbol{b}(\boldsymbol{a})\)</span>.</p>
</div>
<div class="section" id="oblique-projections-onto-a-vector">
<h3><span class="section-number">6.4.1.2. </span>Oblique projections onto a vector<a class="headerlink" href="#oblique-projections-onto-a-vector" title="Permalink to this headline">¶</a></h3>
<p>While orthogonal projections are commonly used, and in many ways special, they are not the only way we can project onto a vector. Indeed, we can define a projection of a vector <span class="math notranslate nohighlight">\(\boldsymbol{a}\)</span> onto another vector <span class="math notranslate nohighlight">\(\boldsymbol{b}\)</span> not just along the direction orthogonal to <span class="math notranslate nohighlight">\(\boldsymbol{b}\)</span>, but along any arbitrary direction. The projection of a vector <span class="math notranslate nohighlight">\(\boldsymbol{a}\)</span> onto the vector <span class="math notranslate nohighlight">\(\boldsymbol{b}\)</span> <em>along the direction perpendicular to <span class="math notranslate nohighlight">\(\boldsymbol{c}\)</span></em> is given by the following:</p>
<div class="math notranslate nohighlight">
\[
\text{proj}_{\boldsymbol{b},\boldsymbol{c}}(\boldsymbol{a}) = \frac{\boldsymbol{c}^\top \boldsymbol{a}}{\boldsymbol{b}^\top \boldsymbol{c}}\boldsymbol{b}
\]</div>
<p>Again, <span class="math notranslate nohighlight">\(\frac{\boldsymbol{c}^\top \boldsymbol{a}}{\boldsymbol{b}^\top \boldsymbol{c}}\)</span> is just a scalar, so this vector is again just a rescaled version of <span class="math notranslate nohighlight">\(\boldsymbol{b}\)</span>. We can also rearrange this formula to write it as a linear function in terms of a matrix</p>
<div class="math notranslate nohighlight">
\[
\boldsymbol{P}_{\boldsymbol{b},\boldsymbol{c}} = \frac{\boldsymbol{bc}^\top}{\boldsymbol{b}^\top \boldsymbol{c}}
\]</div>
<p>So that <span class="math notranslate nohighlight">\(\text{proj}_{\boldsymbol{b},\boldsymbol{c}}(\boldsymbol{a}) = \boldsymbol{P}_{\boldsymbol{b},\boldsymbol{c}}\boldsymbol{a}\)</span>. Let’s verify that <span class="math notranslate nohighlight">\(\boldsymbol{P}_{\boldsymbol{b},\boldsymbol{c}}\)</span> also satisfies the idempotence property <span class="math notranslate nohighlight">\(\boldsymbol{P}^2 = \boldsymbol{P}\)</span>.</p>
<div class="math notranslate nohighlight">
\[
\boldsymbol{P}_{\boldsymbol{b},\boldsymbol{c}}^2 = \frac{\boldsymbol{bc}^\top}{\boldsymbol{b}^\top \boldsymbol{c}}\frac{\boldsymbol{bc}^\top}{\boldsymbol{b^\top c}} = \frac{1}{(\boldsymbol{b^\top c})^2}\boldsymbol{bc}^\top \boldsymbol{bc}^\top = \frac{1}{(\boldsymbol{b^\top c})^2}\boldsymbol{b}(\boldsymbol{c^\top b})\boldsymbol{c}^\top = \frac{\boldsymbol{c^\top b}}{(\boldsymbol{b^\top c})^2}\boldsymbol{bc}^\top = \frac{\boldsymbol{bc}^\top}{\boldsymbol{b^\top c}} = \boldsymbol{P}_{\boldsymbol{b},\boldsymbol{c}}.
\]</div>
<p>Indeed, <span class="math notranslate nohighlight">\(\boldsymbol{P}_{\boldsymbol{b},\boldsymbol{c}}\)</span> is also a valid projection. So then what is the difference between <span class="math notranslate nohighlight">\(\boldsymbol{P}_{\boldsymbol{b},\boldsymbol{c}}\)</span> and the orthogonal projection <span class="math notranslate nohighlight">\(\boldsymbol{P}_\boldsymbol{b}\)</span> that we saw before? The difference lies in the fact that the <em>residuals</em> are no longer orthogonal; that is, the angle between <span class="math notranslate nohighlight">\(\text{proj}_{\boldsymbol{b},\boldsymbol{c}}(\boldsymbol{a})\)</span> and <span class="math notranslate nohighlight">\(\boldsymbol{a} - \text{proj}_{\boldsymbol{b},\boldsymbol{c}}(\boldsymbol{a})\)</span> is no longer <span class="math notranslate nohighlight">\(90^\circ\)</span>. Let’s check that this.</p>
<div class="math notranslate nohighlight">
\[
\text{proj}_{\boldsymbol{b},\boldsymbol{c}}(\boldsymbol{a})^\top (\boldsymbol{a} - \text{proj}_{\boldsymbol{b},\boldsymbol{c}}(\boldsymbol{a})) = \left(\frac{\boldsymbol{c^\top a}}{\boldsymbol{b^\top c}}\boldsymbol{b}\right)^\top\left(\boldsymbol{a} - \frac{\boldsymbol{c^\top a}}{\boldsymbol{b^\top c}}\boldsymbol{b}\right) = \frac{\boldsymbol{c^\top a}}{\boldsymbol{b^\top c}}\left(\boldsymbol{b^\top a} - \frac{\boldsymbol{c^\top a}}{\boldsymbol{b^\top c}}\boldsymbol{b^\top b}\right)
\]</div>
<p>This quantity will only be zero for any <span class="math notranslate nohighlight">\(\boldsymbol{a}\)</span> if  <span class="math notranslate nohighlight">\(\boldsymbol{b^\top a} - \frac{\boldsymbol{c^\top a}}{\boldsymbol{b^\top c}}\boldsymbol{b^\top b} = 0\)</span>. This happens when <span class="math notranslate nohighlight">\(\boldsymbol{b}=\boldsymbol{c}\)</span>, in which case we return to get the orthogonal projection back, but for any other <span class="math notranslate nohighlight">\(\boldsymbol{c}\)</span> we will not have that the residuals are orthogonal to <span class="math notranslate nohighlight">\(\text{proj}_{\boldsymbol{b},\boldsymbol{c}}(\boldsymbol{a})\)</span>. Therefore, projections of this form are called <em>oblique</em> projections. Let’s see an example in <span class="math notranslate nohighlight">\(\mathbb{R}^2\)</span>.</p>
<p>Let’s write a function to compute <span class="math notranslate nohighlight">\(\text{proj}_{b,c}\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">oblique_projection</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">b</span><span class="p">,</span><span class="n">c</span><span class="p">)</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">b</span><span class="p">,</span><span class="n">c</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s again project the vector <span class="math notranslate nohighlight">\(\boldsymbol{b}=\begin{bmatrix}1\\1\end{bmatrix}\)</span> onto the vector <span class="math notranslate nohighlight">\(\boldsymbol{b}=\begin{bmatrix}1\\2\end{bmatrix}\)</span>, but this time along the direction <span class="math notranslate nohighlight">\(\boldsymbol{c} =\begin{bmatrix}1\\1/4\end{bmatrix}\)</span>. First, we’ll compute <span class="math notranslate nohighlight">\(\boldsymbol{P}_{\boldsymbol{b},\boldsymbol{c}}\)</span> using our oblique projection function.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mf">0.25</span><span class="p">])</span>

<span class="n">Pbc</span> <span class="o">=</span> <span class="n">oblique_projection</span><span class="p">(</span><span class="n">b</span><span class="p">,</span><span class="n">c</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s verify that <span class="math notranslate nohighlight">\(\boldsymbol{P}_{\boldsymbol{b},\boldsymbol{c}}^2 = \boldsymbol{P}_{\boldsymbol{b},\boldsymbol{c}}\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Pbc2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Pbc</span><span class="p">,</span> <span class="n">Pbc</span><span class="p">)</span>

<span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">Pbc2</span><span class="p">,</span> <span class="n">Pbc</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>True
</pre></div>
</div>
</div>
</div>
<p>So <span class="math notranslate nohighlight">\(\boldsymbol{P}_{\boldsymbol{b},\boldsymbol{c}}\)</span> is indeed idempotent. Now let’s visualize <span class="math notranslate nohighlight">\(\boldsymbol{a},\boldsymbol{b}, \text{proj}_{\boldsymbol{b},\boldsymbol{c}}(\boldsymbol{a})\)</span> and <span class="math notranslate nohighlight">\(\boldsymbol{a}-\text{proj}_{\boldsymbol{b},\boldsymbol{c}}(\boldsymbol{a})\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">proj_bc_a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Pbc</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span> <span class="c1"># compute the projection of a onto b</span>
<span class="n">residual</span> <span class="o">=</span> <span class="n">a</span> <span class="o">-</span> <span class="n">proj_bc_a</span>

<span class="n">plt</span><span class="o">.</span><span class="n">quiver</span><span class="p">(</span><span class="o">*</span><span class="n">origin</span><span class="p">,</span> <span class="o">*</span><span class="n">b</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">units</span><span class="o">=</span><span class="s1">&#39;xy&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">quiver</span><span class="p">(</span><span class="o">*</span><span class="n">origin</span><span class="p">,</span> <span class="o">*</span><span class="n">a</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">units</span><span class="o">=</span><span class="s1">&#39;xy&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">quiver</span><span class="p">(</span><span class="o">*</span><span class="n">origin</span><span class="p">,</span> <span class="o">*</span><span class="n">proj_bc_a</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;proj_bc(a)&#39;</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">units</span><span class="o">=</span><span class="s1">&#39;xy&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">quiver</span><span class="p">(</span><span class="o">*</span><span class="n">proj_bc_a</span><span class="p">,</span> <span class="o">*</span><span class="n">residual</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;a - proj_bc(a)&#39;</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">units</span><span class="o">=</span><span class="s1">&#39;xy&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;orange&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mf">1.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mf">2.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">set_aspect</span><span class="p">(</span><span class="s1">&#39;equal&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper left&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/basicLA_4_projections_17_0.png" src="../_images/basicLA_4_projections_17_0.png" />
</div>
</div>
<p>In this plot, we see that <span class="math notranslate nohighlight">\(\text{proj}_{\boldsymbol{b},\boldsymbol{c}}(\boldsymbol{a})\)</span> is indeed parallel to <span class="math notranslate nohighlight">\(\boldsymbol{b}\)</span>, but it is not at a <span class="math notranslate nohighlight">\(90^\circ\)</span> angle from the residual <span class="math notranslate nohighlight">\(\boldsymbol{a}-\text{proj}_{\boldsymbol{b},\boldsymbol{c}}(\boldsymbol{a})\)</span>. Let’s actually compute the angle between <span class="math notranslate nohighlight">\(\text{proj}_{\boldsymbol{b},\boldsymbol{c}}(\boldsymbol{a})\)</span> and <span class="math notranslate nohighlight">\(\boldsymbol{a}-\text{proj}_{\boldsymbol{b},\boldsymbol{c}}(\boldsymbol{a})\)</span> using techniques that we learned earlier in the chapter (recall that the angle between vectors <span class="math notranslate nohighlight">\(\boldsymbol{x}\)</span> and <span class="math notranslate nohighlight">\(\boldsymbol{y}\)</span> is <span class="math notranslate nohighlight">\(\arccos\left(\frac{\boldsymbol{x^\top y}}{\|\boldsymbol{x}\|_2\|\boldsymbol{y}\|_2}\right)\)</span>).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">temp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">proj_bc_a</span><span class="p">,</span> <span class="n">residual</span><span class="p">)</span>
<span class="n">residual_norm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">residual</span><span class="p">)</span>
<span class="n">proj_bc_a_norm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">proj_bc_a</span><span class="p">)</span>

<span class="n">angle</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arccos</span><span class="p">(</span><span class="n">temp</span><span class="o">/</span><span class="p">(</span><span class="n">residual_norm</span><span class="o">*</span><span class="n">proj_bc_a_norm</span><span class="p">))</span>
<span class="n">angle</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2.4329663814621227
</pre></div>
</div>
</div>
</div>
<p>Indeed, we get that the angle between <span class="math notranslate nohighlight">\(\text{proj}_{\boldsymbol{b},\boldsymbol{c}}(\boldsymbol{a})\)</span> and <span class="math notranslate nohighlight">\(\boldsymbol{a}-\text{proj}_{\boldsymbol{b},\boldsymbol{c}}(\boldsymbol{a})\)</span> is approximately <span class="math notranslate nohighlight">\(2.43\)</span> radians, which is roughly <span class="math notranslate nohighlight">\(140^\circ\)</span>.</p>
</div>
</div>
<div class="section" id="projections-onto-a-subspace">
<h2><span class="section-number">6.4.2. </span>Projections onto a subspace<a class="headerlink" href="#projections-onto-a-subspace" title="Permalink to this headline">¶</a></h2>
<p>In the above sections, we phrased projections as projecting a vector <span class="math notranslate nohighlight">\(\boldsymbol{a}\)</span> onto another <em>vector</em> <span class="math notranslate nohighlight">\(\boldsymbol{b}\)</span>. In reality, what we computed was actually the projection of <span class="math notranslate nohighlight">\(\boldsymbol{a}\)</span> onto the <em>subspace</em> <span class="math notranslate nohighlight">\(V = \text{span}(\boldsymbol{b})\)</span>.</p>
<p>It turns out that there’s nothing special about projecting onto a <span class="math notranslate nohighlight">\(1\)</span>-dimensional subspace: we can define orthogonal and oblique projections onto any subspace, as we will see below.</p>
<div class="section" id="orthogonal-projections-onto-a-subspace">
<h3><span class="section-number">6.4.2.1. </span>Orthogonal projections onto a subspace<a class="headerlink" href="#orthogonal-projections-onto-a-subspace" title="Permalink to this headline">¶</a></h3>
<p>Let’s begin with the concept of an orthogonal projection onto a subspace. Let <span class="math notranslate nohighlight">\(V\)</span> be a subspace of <span class="math notranslate nohighlight">\(\mathbb{R}^n\)</span>, spanned by vectors <span class="math notranslate nohighlight">\(\boldsymbol{a}_1,\dots, \boldsymbol{a}_k\)</span>. Let’s let <span class="math notranslate nohighlight">\(\boldsymbol{A}\)</span> be the matrix whose columns are <span class="math notranslate nohighlight">\(\boldsymbol{a}_1,\dots, \boldsymbol{a}_k\)</span>, i.e.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\boldsymbol{A} = \begin{bmatrix} | &amp; | &amp;&amp; |\\ \boldsymbol{a}_1 &amp; \boldsymbol{a}_2 &amp; \cdots &amp; \boldsymbol{a}_k \\ | &amp; | &amp; &amp; |\end{bmatrix}
\end{split}\]</div>
<p>Let’s see how we can derive the orthogonal projection onto <span class="math notranslate nohighlight">\(V\)</span>, which is just the column space of <span class="math notranslate nohighlight">\(\boldsymbol{A}\)</span>. Consider projecting a vector <span class="math notranslate nohighlight">\(\boldsymbol{b}\)</span> onto <span class="math notranslate nohighlight">\(V\)</span> – call this projection <span class="math notranslate nohighlight">\(\hat{\boldsymbol{b}} = \text{proj}_V(\boldsymbol{b})\)</span>. Since <span class="math notranslate nohighlight">\(\hat{\boldsymbol{b}}\)</span> should belong to the column space of <span class="math notranslate nohighlight">\(\boldsymbol{A}\)</span>, it should be of the form <span class="math notranslate nohighlight">\(\hat{\boldsymbol{b}} = \boldsymbol{A}\hat{\boldsymbol{x}}\)</span> for some vector <span class="math notranslate nohighlight">\(\hat{\boldsymbol{x}}.\)</span> For this projection to be orthogonal, we want that <span class="math notranslate nohighlight">\(\boldsymbol{b}- \hat{\boldsymbol{b}} =\boldsymbol{b}-\boldsymbol{A}\hat{\boldsymbol{x}}\)</span> to be orthogonal to all the columns of <span class="math notranslate nohighlight">\(\boldsymbol{A}\)</span>. Earlier in the chapter, we saw that this means that <span class="math notranslate nohighlight">\(\boldsymbol{A}^\top(\boldsymbol{b} - \boldsymbol{A}\hat{\boldsymbol{x}}) = 0\)</span>. Then</p>
<div class="math notranslate nohighlight">
\[
\boldsymbol{A^\top}(\boldsymbol{b}-\boldsymbol{A} \hat{\boldsymbol{x}}) = 0 \iff \boldsymbol{A^\top b} = \boldsymbol{A^\top A}\hat{\boldsymbol{x}} \iff \hat{\boldsymbol{x}} = (\boldsymbol{A^\top A})^{-1}\boldsymbol{A^\top b}
\]</div>
<p>Since <span class="math notranslate nohighlight">\(\hat{\boldsymbol{b}} = \boldsymbol{A}\hat{\boldsymbol{x}}\)</span>, we get</p>
<div class="math notranslate nohighlight">
\[
\text{proj}_V(\boldsymbol{b}) = \hat{\boldsymbol{b}} = \boldsymbol{A}\hat{\boldsymbol{x}} = \boldsymbol{A}(\boldsymbol{A^\top A})^{-1}\boldsymbol{A}^\top \boldsymbol{b}
\]</div>
<p>This immediately gives us a formula for the projection matrix <span class="math notranslate nohighlight">\(\boldsymbol{P}_V\)</span>:</p>
<div class="math notranslate nohighlight">
\[
\boldsymbol{P}_V = \boldsymbol{A}(\boldsymbol{A^\top A})^{-1}\boldsymbol{A}^\top
\]</div>
<p>This is an important formula that we will see again later in the semester. Let’s check that <span class="math notranslate nohighlight">\(\boldsymbol{P}_V\)</span> satisfies the idempotence condition <span class="math notranslate nohighlight">\(\boldsymbol{P}_V^2 = \boldsymbol{P}_V\)</span>. We have</p>
<div class="math notranslate nohighlight">
\[
\boldsymbol{P}_V^2 = \boldsymbol{A}(\boldsymbol{A^\top A})^{-1}\underbrace{\boldsymbol{A^\top A}(\boldsymbol{A^\top A})^{-1}}_{\boldsymbol{I}}\boldsymbol{A}^\top = \boldsymbol{A}(\boldsymbol{A^\top A})^{-1}\boldsymbol{A}^\top = \boldsymbol{P}_V
\]</div>
<p>Indeed it does. Now let’s look at an example numerically. Consider the matrix</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\boldsymbol{A} =\begin{bmatrix} \boldsymbol{a}_1 &amp; \boldsymbol{a}_2\end{bmatrix} = \begin{bmatrix} 1 &amp; 0\\ 1 &amp; 1 \\ 0 &amp;1\end{bmatrix}
\end{split}\]</div>
<p>Where here <span class="math notranslate nohighlight">\(\boldsymbol{a}_1 = \begin{bmatrix}1\\1\\0\end{bmatrix}\)</span> and <span class="math notranslate nohighlight">\(\boldsymbol{a}_2 = \begin{bmatrix}0\\ 1\\1\end{bmatrix}\)</span>. Let’s compute the projection onto <span class="math notranslate nohighlight">\(V = \text{span}(\boldsymbol{a}_1,\boldsymbol{a}_2)\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]])</span>
<span class="n">ATA_inv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">A</span><span class="p">))</span> <span class="c1"># compute (A^TA)^{-1}</span>
<span class="n">PV</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">ATA_inv</span><span class="p">,</span> <span class="n">A</span><span class="o">.</span><span class="n">T</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s verify that this worked, by checking numerically that <span class="math notranslate nohighlight">\(P_V^2 = P_V\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">PV2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">PV</span><span class="p">,</span> <span class="n">PV</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">PV2</span><span class="p">,</span> <span class="n">PV</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>True
</pre></div>
</div>
</div>
</div>
<p>Indeed it does.</p>
<p>Let’s now verify that this projection is orthogonal to the column space of <span class="math notranslate nohighlight">\(\boldsymbol{A}\)</span>, by computing <span class="math notranslate nohighlight">\(\boldsymbol{A}^\top(\boldsymbol{b} - \text{proj}_V(\boldsymbol{b}))\)</span>. For this example, we’ll use the vector <span class="math notranslate nohighlight">\(\boldsymbol{b} = \begin{bmatrix}1\\ 2\\ 3\end{bmatrix}\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">])</span>

<span class="n">proj_V_b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">PV</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
<span class="n">residual</span> <span class="o">=</span> <span class="n">b</span> <span class="o">-</span> <span class="n">proj_V_b</span>

<span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">residual</span><span class="p">)</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">8</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([0., 0.])
</pre></div>
</div>
</div>
</div>
<p>Indeed, we get the zeros vector, and so <span class="math notranslate nohighlight">\(\boldsymbol{b}-\text{proj}_V(\boldsymbol{b})\)</span> is orthogonal to the columns of <span class="math notranslate nohighlight">\(\boldsymbol{A}\)</span>.</p>
<div class="section" id="relationship-with-the-qr-decomposition">
<h4><span class="section-number">6.4.2.1.1. </span>Relationship with the QR decomposition<a class="headerlink" href="#relationship-with-the-qr-decomposition" title="Permalink to this headline">¶</a></h4>
<p>In the previous workbook, we saw that we can write any matrix <span class="math notranslate nohighlight">\(\boldsymbol{A}\)</span> as <span class="math notranslate nohighlight">\(\boldsymbol{A} = \boldsymbol{QR}\)</span> where <span class="math notranslate nohighlight">\(\boldsymbol{Q}\)</span> is an orthogonal matrix and <span class="math notranslate nohighlight">\(\boldsymbol{R}\)</span> is upper triangular. Here, we’ll see that we can write the projection onto the column space conveniently in terms of <span class="math notranslate nohighlight">\(\boldsymbol{Q}\)</span>. Let’s plug in <span class="math notranslate nohighlight">\(\boldsymbol{A} = \boldsymbol{QR}\)</span> into our formula for <span class="math notranslate nohighlight">\(\boldsymbol{P}_V\)</span> (and recall that <span class="math notranslate nohighlight">\(\boldsymbol{Q^\top Q} = \boldsymbol{I}\)</span>).</p>
<div class="math notranslate nohighlight">
\[
\boldsymbol{P}_V = \boldsymbol{QR}((\boldsymbol{QR})^\top \boldsymbol{QR})^{-1}(\boldsymbol{QR})^\top = \boldsymbol{QR}(\boldsymbol{R}^\top \underbrace{\boldsymbol{Q^\top Q}}_{\boldsymbol{I}} \boldsymbol{R})^{-1}\boldsymbol{R^\top Q}^\top = \boldsymbol{QR}(\boldsymbol{R^\top R})^{-1}\boldsymbol{R^\top Q}^\top = \boldsymbol{Q}\underbrace{\boldsymbol{RR}^{-1}}_{\boldsymbol{I}}\underbrace{(\boldsymbol{R}^\top)^{-1}\boldsymbol{R}^\top}_{\boldsymbol{I}} \boldsymbol{Q}^\top = \boldsymbol{QQ}^\top
\]</div>
<p>Therefore, if we have the QR decomposition of <span class="math notranslate nohighlight">\(\boldsymbol{A}\)</span>, the projection onto the column space of <span class="math notranslate nohighlight">\(\boldsymbol{A}\)</span> can be easily computed with <span class="math notranslate nohighlight">\(\boldsymbol{QQ}^\top\)</span>. This is convenient as it doesn’t require taking any matrix inverses, which can be difficult to work with numerically.</p>
<p><strong>Remark:</strong> Recall that we always have that <span class="math notranslate nohighlight">\(\boldsymbol{Q^\top Q} = \boldsymbol{I}\)</span> for an orthogonal matrix <span class="math notranslate nohighlight">\(\boldsymbol{Q}\)</span>. Here we see clearly that <span class="math notranslate nohighlight">\(\boldsymbol{QQ}^\top\)</span> is emphatically <em>not</em> equal to the identity in general.</p>
<p>Let’s use this method to compute the projection <span class="math notranslate nohighlight">\(\boldsymbol{P}_V\)</span> using the same matrix <span class="math notranslate nohighlight">\(\boldsymbol{A}\)</span> as above. Here we use the built-in numpy function for the QR decomposition, but we could just as well have used the QR function that we wrote ourselves in the previous workbook.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Q</span><span class="p">,</span> <span class="n">R</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">qr</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="n">QQT</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Q</span><span class="p">,</span> <span class="n">Q</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">QQT</span><span class="p">,</span> <span class="n">PV</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>True
</pre></div>
</div>
</div>
</div>
<p>Indeed, the two approaches give us the same answer.</p>
<p>The last point we make before moving on is that there are <em>many</em> possible matrices <span class="math notranslate nohighlight">\(\boldsymbol{A}\)</span> whose columns span a given subspace <span class="math notranslate nohighlight">\(V\)</span>. For example, the matrix</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\boldsymbol{B} = \begin{bmatrix} -2 &amp; 0\\ -2 &amp; 4 \\ 0 &amp;4\end{bmatrix}
\end{split}\]</div>
<p>has the same column space as <span class="math notranslate nohighlight">\(\boldsymbol{A}\)</span>. Let’s check that computing the projection using this matrix gives us the same result.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">B</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">]])</span>

<span class="n">Q2</span><span class="p">,</span> <span class="n">R2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">qr</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>
<span class="n">QQT2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Q2</span><span class="p">,</span> <span class="n">Q2</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">QQT</span><span class="p">,</span> <span class="n">QQT2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>True
</pre></div>
</div>
</div>
</div>
<p>Indeed, the projection onto <span class="math notranslate nohighlight">\(V\)</span> is the same no matter which spanning vectors we use.</p>
</div>
</div>
<div class="section" id="oblique-projections-onto-a-subspace">
<h3><span class="section-number">6.4.2.2. </span>Oblique projections onto a subspace<a class="headerlink" href="#oblique-projections-onto-a-subspace" title="Permalink to this headline">¶</a></h3>
<p>Like in the case of projecting onto vectors, we can also have <em>oblique</em> projections onto the column space of a matrix <span class="math notranslate nohighlight">\(\boldsymbol{A}\)</span>, which is the subspace <span class="math notranslate nohighlight">\(V\)</span>. Let <span class="math notranslate nohighlight">\(\boldsymbol{C}\)</span> be any <span class="math notranslate nohighlight">\(n\times k\)</span> matrix such that <span class="math notranslate nohighlight">\(\boldsymbol{C^\top A}\)</span> is invertible. Then the matrix</p>
<div class="math notranslate nohighlight">
\[
P_{V,\boldsymbol{C}} = \boldsymbol{A}(\boldsymbol{C^\top A})^{-1}\boldsymbol{C}^\top
\]</div>
<p>is always a projection onto <span class="math notranslate nohighlight">\(V\)</span>. It will of course reduce to the orthogonal projection when <span class="math notranslate nohighlight">\(\boldsymbol{C} = \boldsymbol{A}\)</span>, in which case we obtain the same  formula that we had before. To check that it is indeed a projection, we need to verify that <span class="math notranslate nohighlight">\(\boldsymbol{P}_{V,\boldsymbol{C}}^2 = \boldsymbol{P}_{V,\boldsymbol{C}}\)</span>. We calculate</p>
<div class="math notranslate nohighlight">
\[
\boldsymbol{P}_{V,\boldsymbol{C}}^2 = \boldsymbol{A}(\boldsymbol{C^\top A})^{-1}\underbrace{\boldsymbol{C^\top A}(\boldsymbol{C^\top A})^{-1}}_{\boldsymbol{I}}\boldsymbol{C}^\top = \boldsymbol{A}(\boldsymbol{C^\top A})^{-1}\boldsymbol{C}^\top = \boldsymbol{P}_{V,\boldsymbol{C}}
\]</div>
<p>So <span class="math notranslate nohighlight">\(\boldsymbol{P}_{V,\boldsymbol{C}}\)</span> is in fact a valid projection. Let’s first look at an example with the matrix <span class="math notranslate nohighlight">\(\boldsymbol{A} = \begin{bmatrix} 1 &amp; 0\\ 1 &amp; 1 \\ 0 &amp;1\end{bmatrix}\)</span> that we used above. There are many valid examples of matrices <span class="math notranslate nohighlight">\(\boldsymbol{C}\)</span> that we can use to define an oblique projection <span class="math notranslate nohighlight">\(\boldsymbol{P}_{V,\boldsymbol{C}}\)</span>; indeed, for most matrices <span class="math notranslate nohighlight">\(\boldsymbol{C}\)</span> we will have that <span class="math notranslate nohighlight">\(\boldsymbol{C^\top A}\)</span> is invertible. Let’s try choosing <span class="math notranslate nohighlight">\(\boldsymbol{C}\)</span> to be a random matrix.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">k</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">3</span>

<span class="n">C</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">k</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s check that <span class="math notranslate nohighlight">\(\boldsymbol{C^\top A}\)</span> is invertible.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">CTA_inv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">C</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">A</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>Indeed, computing the inverse works without error.</p>
<p>Now, let’s use this to compute <span class="math notranslate nohighlight">\(\boldsymbol{P}_{V,\boldsymbol{C}}\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">PVC</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">CTA_inv</span><span class="p">,</span> <span class="n">C</span><span class="o">.</span><span class="n">T</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>We can check numerically that <span class="math notranslate nohighlight">\(\boldsymbol{P}_{V,\boldsymbol{C}}^2 = \boldsymbol{P}_{V,\boldsymbol{C}}\)</span>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">PVC2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">PVC</span><span class="p">,</span> <span class="n">PVC</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">PVC2</span><span class="p">,</span> <span class="n">PVC</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>True
</pre></div>
</div>
</div>
</div>
<p>So <span class="math notranslate nohighlight">\(\boldsymbol{P}_{V,\boldsymbol{C}}\)</span> is in fact idempotent, and thus a valid projection. However, it is not orthogonal; we can check this by computing <span class="math notranslate nohighlight">\(\boldsymbol{A}^\top (\boldsymbol{b} - \boldsymbol{P}_{V,\boldsymbol{C}}\boldsymbol{b})\)</span>, and verifying that it is not equal to zero (as it was in the orthogonal case). Let’s do this for the same vector <span class="math notranslate nohighlight">\(\boldsymbol{b} = \begin{bmatrix}1\\ 2\\ 3\end{bmatrix}\)</span> that we used before.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">proj_VC_b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">PVC</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
<span class="n">residuals</span> <span class="o">=</span> <span class="n">b</span> <span class="o">-</span> <span class="n">proj_VC_b</span>
<span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">residuals</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([-2.06215663,  5.40986263])
</pre></div>
</div>
</div>
</div>
<p>Our answer is clearly not zero, and so the projection <span class="math notranslate nohighlight">\(\boldsymbol{P}_{V,\boldsymbol{C}}\)</span> is <em>not</em> an orthogonal projection, but rather an <em>oblique</em> projection.</p>
</div>
</div>
<div class="section" id="projecting-onto-the-orthogonal-complement-of-a-subspace">
<h2><span class="section-number">6.4.3. </span>Projecting onto the orthogonal complement of a subspace<a class="headerlink" href="#projecting-onto-the-orthogonal-complement-of-a-subspace" title="Permalink to this headline">¶</a></h2>
<p>The last type of projection we will discuss is the projection onto the <em>orthogonal complement</em> of a subspace <span class="math notranslate nohighlight">\(V\subseteq \mathbb{R}^n\)</span>. The orthogonal complement is the subspace <span class="math notranslate nohighlight">\(V^\perp\)</span> which is defined as follows:</p>
<div class="math notranslate nohighlight">
\[
V^\perp = \{\boldsymbol{w}\in \mathbb{R}^n : \boldsymbol{w^\top v} = 0\text{ for all } \boldsymbol{v}\in V\}
\]</div>
<p>That is, the orthogonal complement of <span class="math notranslate nohighlight">\(V\)</span> is the set of all vectors which are orthogonal to all vectors in <span class="math notranslate nohighlight">\(V\)</span>. It turns out that the projection onto the orthogonal complement is easy to find given the orthogonal projection onto <span class="math notranslate nohighlight">\(V\)</span>. If <span class="math notranslate nohighlight">\(\boldsymbol{P}_V\)</span> is the orthogonal projection onto <span class="math notranslate nohighlight">\(V\)</span>, then the orthogonal projection onto <span class="math notranslate nohighlight">\(V^\perp\)</span> is just</p>
<div class="math notranslate nohighlight">
\[
\boldsymbol{P}_{V^\perp} = \boldsymbol{I} - \boldsymbol{P}_V
\]</div>
<p>Given <span class="math notranslate nohighlight">\(\boldsymbol{P}_V = \boldsymbol{A}(\boldsymbol{A^\top A})^{-1}\boldsymbol{A}^\top\)</span> or <span class="math notranslate nohighlight">\(\boldsymbol{P}_V = \boldsymbol{QQ}^\top\)</span> (where <span class="math notranslate nohighlight">\(\boldsymbol{Q}\)</span> comes from the QR factorization of <span class="math notranslate nohighlight">\(\boldsymbol{A}\)</span>), this means <span class="math notranslate nohighlight">\(\boldsymbol{P}_{V^\perp} = \boldsymbol{I}- \boldsymbol{A}(\boldsymbol{A^\top A})^{-1}\boldsymbol{A}^\top\)</span> or <span class="math notranslate nohighlight">\(\boldsymbol{P}_{V^\perp} = \boldsymbol{I}- \boldsymbol{QQ}^\top\)</span>. Since the range of <span class="math notranslate nohighlight">\(\boldsymbol{P}_V\)</span> is <span class="math notranslate nohighlight">\(V\)</span>, and the range of <span class="math notranslate nohighlight">\(\boldsymbol{P}_{V^\perp}\)</span> is <span class="math notranslate nohighlight">\(V^\perp\)</span>, we should always have that <span class="math notranslate nohighlight">\(\boldsymbol{P}_V \boldsymbol{x}\)</span> is orthogonal to <span class="math notranslate nohighlight">\(\boldsymbol{P}_{V^\perp}\boldsymbol{y}\)</span> for any vectors <span class="math notranslate nohighlight">\(\boldsymbol{x}\)</span> and <span class="math notranslate nohighlight">\(\boldsymbol{y}\)</span>. Let’s check that this is in fact true. We have</p>
<div class="math notranslate nohighlight">
\[
(\boldsymbol{P}_{V^\perp}\boldsymbol{y})^\top \boldsymbol{P}_{V}\boldsymbol{x} = \boldsymbol{y}^\top \boldsymbol{P}_{V^\perp}\boldsymbol{P}_V\boldsymbol{x} = \boldsymbol{y}^\top (\boldsymbol{I}-\boldsymbol{P}_V)\boldsymbol{P}_V\boldsymbol{x} = \boldsymbol{y}^\top \boldsymbol{P}_V\boldsymbol{x} - \boldsymbol{y}^\top \boldsymbol{P}_V^2\boldsymbol{x} = \boldsymbol{y}^\top \boldsymbol{P}_V\boldsymbol{x} - \boldsymbol{y}^\top \boldsymbol{P}_V \boldsymbol{x} = 0
\]</div>
<p>where we used the fact that <span class="math notranslate nohighlight">\(\boldsymbol{P}_V\)</span> is a projection, so <span class="math notranslate nohighlight">\(\boldsymbol{P}_V^2 = \boldsymbol{P}_V\)</span>.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./content"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="basicLA_4_QR_linear_systems.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">6.3. </span>Solving linear systems with the QR decomposition</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="eigenstuff_chheader.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">7. </span>Eigenthings</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Michael W. Mahoney, N. Benjamin Erichson and Ryan Theisen<br/>
    
        &copy; Copyright 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>