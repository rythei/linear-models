
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>7.6. Low-Rank Approximation Using the SVD &#8212; Linear Algebra for Data Workbook</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="prev" title="7.5. The Singular Value Decomposition" href="eigenstuff_SVD.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Linear Algebra for Data Workbook</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../overview.html">
   Welcome to Stat 89A
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Background
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="python_chheader.html">
   1. Python 101
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="python_basics.html">
     1.1. The Basics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="python_numpy.html">
     1.2. Introduction to NumPy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="python_plotting.html">
     1.3. MatPlotLib
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Basic Linear Algebra
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="basicLA_1_chheader.html">
   2. Matrices, vectors, and
   <span class="math notranslate nohighlight">
    \(\mathbb{R}^n\)
   </span>
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="basicLA_1_introduction-to-norms.html">
     2.1. Introduction to Norms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="basicLA_1_norms-integration-monte-carlo.html">
     2.2. An application: approximating integrals with norms and Monte Carlo integration
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="basicLA_1_lp-balls.html">
     2.3.
     <span class="math notranslate nohighlight">
      \(\ell_p\)
     </span>
     Balls
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="basicLA_1_classification-with-norms.html">
     2.4. An application: classifying data points using norms
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="basicLA_2_chheader.html">
   3. Basics of vectors and vector spaces
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="basicLA_2A_vectorspaces.html">
     3.1. Vectors and vector spaces
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="basicLA_3_chheader.html">
   4. Basics of matrices
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="basicLA_3_matrices-and-matrix-operations.html">
     4.1. Matrices and matrix operations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="basicLA_3_deconstructing.html">
     4.2. Deconstructing Matrix Multiplication
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="basicLA_3_powers_of_matrices.html">
     4.3. Taking Powers of Matrices
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="basicLA_3B_chheader.html">
   5. Matrices as transformations
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="basicLA_3_linear_examples_new.html">
     5.1. Linear and Nonlinear Functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="basicLA_3_matrices_and_linear_functions.html">
     5.2. Matrices and Linear Functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="basicLA_3_injective-and-surjective-functions.html">
     5.3. Injective, surjective and invertible functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="basicLA_3_inverses.html">
     5.4. Left Inverses, Right Inverses, and Inverses
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="basicLA_3_changing_basis.html">
     5.5. Changing Basis
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="basicLA_4_chheader.html">
   6. Geometry: angles, orthogonality, and projections
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="basicLA_4_dot-products-and-angles.html">
     6.1. Dot products, angles, and orthogonality
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="basicLA_4_QR.html">
     6.2. Gram–Schmidt and the QR Decomposition
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="basicLA_4_QR_linear_systems.html">
     6.3. Solving linear systems with the QR decomposition
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="basicLA_4_projections.html">
     6.4. Projections
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Eigenthings, the spectral theorem, and the singular value decomposition
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="eigenstuff_chheader.html">
   7. Eigenstuff
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="eigenstuff_quadratic-forms.html">
     7.1. Quadratic forms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="eigenstuff_eigenthings.html">
     7.2. Eigenvalues and eigenvectors
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="eigenstuff_eigenthings-special-matrices.html">
     7.3. The Eigenvalue decomposition for special types of matrices
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="eigenstuff_qr-algorithm.html">
     7.4. The QR algorithm for finding eigenvalues and eigenvectors
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="eigenstuff_SVD.html">
     7.5. The Singular Value Decomposition
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     7.6. Low-Rank Approximation Using the SVD
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        <a class="dropdown-buttons"
            href="../_sources/content/eigenstuff_image-compression.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download notebook file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/content/eigenstuff_image-compression.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/erichson/LinearAlgebra/master?urlpath=tree/content/eigenstuff_image-compression.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#approximating-matrices-with-the-svd">
   7.6.1. Approximating matrices with the SVD
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#an-example-with-image-compression">
   7.6.2. An example with image compression
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Low-Rank Approximation Using the SVD</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#approximating-matrices-with-the-svd">
   7.6.1. Approximating matrices with the SVD
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#an-example-with-image-compression">
   7.6.2. An example with image compression
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="low-rank-approximation-using-the-svd">
<h1><span class="section-number">7.6. </span>Low-Rank Approximation Using the SVD<a class="headerlink" href="#low-rank-approximation-using-the-svd" title="Permalink to this headline">¶</a></h1>
<p>In the previous section, we saw that the singular value decomposition (SVD) represents any <span class="math notranslate nohighlight">\(m\times n\)</span> matrix <span class="math notranslate nohighlight">\(\boldsymbol{A}\)</span> as <span class="math notranslate nohighlight">\(\boldsymbol{U\Sigma V}^\top\)</span> where <span class="math notranslate nohighlight">\(\boldsymbol{U}, \boldsymbol{V}\)</span> are orthogonal matrices containing the left and right singular vectors of <span class="math notranslate nohighlight">\(\boldsymbol{A}\)</span>, and <span class="math notranslate nohighlight">\(\boldsymbol{\Sigma}\)</span> is a “rectangular-diagonal” matrix containing the singular values of <span class="math notranslate nohighlight">\(\boldsymbol{A}\)</span>. In this section we see an application of the SVD to image compression.</p>
<div class="section" id="approximating-matrices-with-the-svd">
<h2><span class="section-number">7.6.1. </span>Approximating matrices with the SVD<a class="headerlink" href="#approximating-matrices-with-the-svd" title="Permalink to this headline">¶</a></h2>
<p>While the singular value decomposition appears frequently in statistics and machine learning, one of the most important uses of the SVD is in <em>low-rank approximation</em>.</p>
<p>Before explaining the problem of low-rank approximation, let’s first state a few useful facts. Let’s assume that <span class="math notranslate nohighlight">\(\boldsymbol{A}\)</span> is an <span class="math notranslate nohighlight">\(m\times n\)</span> matrix with rank <span class="math notranslate nohighlight">\(r\)</span> (i.e. <span class="math notranslate nohighlight">\(r\)</span> non-zero singular values) and that <span class="math notranslate nohighlight">\(\boldsymbol{A} = \boldsymbol{U\Sigma V}^\top\)</span> is its singular value decomposition. Also, let’s label <span class="math notranslate nohighlight">\(\sigma_1,\dots, \sigma_r\)</span> as its (non-zero) singular values, and let <span class="math notranslate nohighlight">\(\boldsymbol{u}_1,\dots,\boldsymbol{u}_r\)</span> be the first <span class="math notranslate nohighlight">\(r\)</span> columns of <span class="math notranslate nohighlight">\(\boldsymbol{U}\)</span> and <span class="math notranslate nohighlight">\(\boldsymbol{v}_1,\dots, \boldsymbol{v}_r\)</span> be the first <span class="math notranslate nohighlight">\(r\)</span> columns of <span class="math notranslate nohighlight">\(\boldsymbol{V}\)</span>. Throughout, we will assume that the singular values are ordered, so that <span class="math notranslate nohighlight">\(\sigma_1 \geq \sigma_2 \geq \cdots \geq \sigma_r\)</span>. Then another way of writing <span class="math notranslate nohighlight">\(\boldsymbol{U\Sigma V}^\top\)</span>, and hence <span class="math notranslate nohighlight">\(\boldsymbol{A}\)</span> is can be written as</p>
<div class="math notranslate nohighlight">
\[
\boldsymbol{A} = \boldsymbol{U\Sigma V}^\top = \sum_{i=1}^r \sigma_i \boldsymbol{u}_i\boldsymbol{v}_i^\top.
\]</div>
<p>Note that each of the terms in the sum is a matrix, <span class="math notranslate nohighlight">\(\boldsymbol{u}_i\boldsymbol{v}_i\)</span>, multiplied by the scalar <span class="math notranslate nohighlight">\(\sigma_i\)</span>. Note that each of these matrices in the sum is a <em>rank-1 matrix</em>, and that the sum is therefore a rank <span class="math notranslate nohighlight">\(r\)</span> matrix. In the problem of low-rank approximation, we want to find a matrix <span class="math notranslate nohighlight">\(\widehat{\boldsymbol{A}}\)</span> which has rank at most <span class="math notranslate nohighlight">\(k \leq r\)</span>, and approximates <span class="math notranslate nohighlight">\(\boldsymbol{A}\)</span> closely, i.e. <span class="math notranslate nohighlight">\(\boldsymbol{A}\approx \widehat{\boldsymbol{A}}\)</span>. Formally, the problem can be written as follows:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\min_{\widehat{\boldsymbol{A}}}&amp;\;\;\;\; \|\boldsymbol{A} - \widehat{\boldsymbol{A}}\|_F &amp;&amp; (1)\\
\text{subject to}&amp;\;\;\;\; \text{rank}(\widehat{\boldsymbol{A}}) \leq k
\end{aligned}
\end{split}\]</div>
<p>Low rank matrices are useful for a variety of reasons, but two important reasons are that 1) they can require less memory to store and 2) we can do faster matrix computations with low rank matrices. It turns out that the solution to the low-rank approximation problem (1) can be exactly constructed from the singular value decomposition. The famous <a class="reference external" href="https://en.wikipedia.org/wiki/Low-rank_approximation">Eckart–Young–Mirsky theorem</a> states that the solution to the problem (1) is explicitly given by the matrix:</p>
<div class="math notranslate nohighlight">
\[
\widehat{\boldsymbol{A}}_k = \sum_{i=1}^k \sigma_i \boldsymbol{u}_i\boldsymbol{v}_i^\top.
\]</div>
<p>That is, the <em>best possible rank <span class="math notranslate nohighlight">\(k\)</span> approximation to <span class="math notranslate nohighlight">\(\boldsymbol{A}\)</span> is given by the matrix which keeps just the top <span class="math notranslate nohighlight">\(k\)</span> singular values of <span class="math notranslate nohighlight">\(\boldsymbol{A}\)</span></em>. Another way to write <span class="math notranslate nohighlight">\(\widehat{\boldsymbol{A}}_k\)</span> is as follows: set <span class="math notranslate nohighlight">\(\boldsymbol{\Sigma}_k\)</span> to be the <span class="math notranslate nohighlight">\(m\times n\)</span> matrix such that</p>
<div class="math notranslate nohighlight">
\[\begin{split}
[\boldsymbol{\Sigma}_k]_{ij} = \begin{cases}\sigma_i &amp; \text{if } i=j \text{ and } i\leq k\\ 0 &amp; \text{otherwise}\end{cases}
\end{split}\]</div>
<p>That is, <span class="math notranslate nohighlight">\(\boldsymbol{\Sigma}_k\)</span> is the same as <span class="math notranslate nohighlight">\(\boldsymbol{\Sigma}\)</span>, except we set the singular values <span class="math notranslate nohighlight">\(\sigma_{k+1},\dots,\sigma_r\)</span> to be equal to zero. Then <span class="math notranslate nohighlight">\(\widehat{\boldsymbol{A}}_k = \boldsymbol{U\Sigma}_k\boldsymbol{V}^\top\)</span>.</p>
<p>When can we expect <span class="math notranslate nohighlight">\(\widehat{\boldsymbol{A}}_k\)</span> to be a good approximation to <span class="math notranslate nohighlight">\(\boldsymbol{A}\)</span>? It turns out that the error <span class="math notranslate nohighlight">\(\|\widehat{\boldsymbol{A}}_k - \boldsymbol{A}\|_F\)</span> is exactly given by <span class="math notranslate nohighlight">\(\sqrt{\sum_{i=k+1}^r \sigma_i^2}\)</span>. Therefore, if the matrix <span class="math notranslate nohighlight">\(\boldsymbol{A}\)</span> has many small singular values, then it can be well approximated by <span class="math notranslate nohighlight">\(\widehat{\boldsymbol{A}}_k\)</span>.</p>
<p>In the next section, we see an example of low rank approximation with compressing an image.</p>
</div>
<div class="section" id="an-example-with-image-compression">
<h2><span class="section-number">7.6.2. </span>An example with image compression<a class="headerlink" href="#an-example-with-image-compression" title="Permalink to this headline">¶</a></h2>
<p>In this section, we look at a simple example of low rank approximation with image compression. Let’s see an example image.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">mpl_toolkits.mplot3d</span> <span class="kn">import</span> <span class="n">Axes3D</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1"># load in an example image to use</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;data/sample_image_1.npy&#39;</span><span class="p">)</span>

<span class="c1"># Display image</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">11</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">cmap</span> <span class="o">=</span> <span class="s1">&#39;gray&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Print shape</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Dimensions:&#39;</span><span class="p">,</span> <span class="n">image</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/eigenstuff_image-compression_1_0.png" src="../_images/eigenstuff_image-compression_1_0.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Dimensions: (427, 640, 3)
</pre></div>
</div>
</div>
</div>
<p>As we can see, this image is of dimension <span class="math notranslate nohighlight">\((427, 640, 3)\)</span>, but let’s simplify the problem a bit and make it grayscaled. We can do this by taking the average over the third axis.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">image</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="c1"># Display image</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">11</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">cmap</span> <span class="o">=</span> <span class="s1">&#39;gray&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Print shape</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Dimensions:&#39;</span><span class="p">,</span> <span class="n">image</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/eigenstuff_image-compression_3_0.png" src="../_images/eigenstuff_image-compression_3_0.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Dimensions: (427, 640)
</pre></div>
</div>
</div>
</div>
<p>Now we can think of this image as a <span class="math notranslate nohighlight">\(427 \times 640\)</span> matrix <span class="math notranslate nohighlight">\(\boldsymbol{A}\)</span>.</p>
<p>Let’s compute the SVD of the image.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">U</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">Vt</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We can check the rank of <span class="math notranslate nohighlight">\(\boldsymbol{A}\)</span> by checking how many non-zero singular values it has.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;rank(A) = </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="n">s</span><span class="p">[</span><span class="n">s</span><span class="o">&gt;</span><span class="mi">0</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>rank(A) = 427
</pre></div>
</div>
</div>
</div>
<p>So <span class="math notranslate nohighlight">\(\boldsymbol{A}\)</span> is a rank <span class="math notranslate nohighlight">\(427\)</span> matrix.</p>
<p>In the following we construct the outerproducts of the first eight singular vectors and values, i.e. the first eight terms <span class="math notranslate nohighlight">\(\sigma_i \boldsymbol{u}_i\boldsymbol{v}_i^\top\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">axs</span> <span class="o">=</span> <span class="n">axs</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">8</span><span class="p">):</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">U</span><span class="p">[:,</span><span class="n">i</span><span class="p">],</span><span class="n">Vt</span><span class="o">.</span><span class="n">T</span><span class="p">[:,</span><span class="n">i</span><span class="p">])</span><span class="o">*</span><span class="n">s</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">cmap</span> <span class="o">=</span> <span class="s1">&#39;gray&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/eigenstuff_image-compression_9_0.png" src="../_images/eigenstuff_image-compression_9_0.png" />
</div>
</div>
<p>These don’t appear to look like much, but when we <em>sum</em> them, we can obtain approximations to the original image at various levels of quality.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">axs</span> <span class="o">=</span> <span class="n">axs</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
<span class="n">idx</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">20</span><span class="p">,</span><span class="mi">40</span><span class="p">,</span><span class="mi">60</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span><span class="mi">200</span><span class="p">,</span> <span class="mi">300</span><span class="p">]:</span>
    <span class="n">outer_products</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">U</span><span class="p">[:,</span><span class="n">j</span><span class="p">],</span><span class="n">Vt</span><span class="o">.</span><span class="n">T</span><span class="p">[:,</span><span class="n">j</span><span class="p">])</span><span class="o">*</span><span class="n">s</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span>
    <span class="n">reconstruction</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">outer_products</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">reconstruction</span><span class="p">,</span> <span class="n">cmap</span> <span class="o">=</span> <span class="s1">&#39;gray&#39;</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;rank k= </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">i</span><span class="p">)</span>
    <span class="n">idx</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="n">fig</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/eigenstuff_image-compression_11_0.png" src="../_images/eigenstuff_image-compression_11_0.png" />
</div>
</div>
<p>As we can see, as soon as we get to rank <span class="math notranslate nohighlight">\(k=40\)</span>, we get a fairly good approximation to the original image, and by rank <span class="math notranslate nohighlight">\(k=200\)</span> the approximation and the original image are nearly indistinguishable visually.</p>
<p>As we mentioned above, the error from the rank <span class="math notranslate nohighlight">\(k\)</span> approximation is given by <span class="math notranslate nohighlight">\(\|\widehat{\boldsymbol{A}}_k-\boldsymbol{A}\|_F = \sqrt{\sum_{i=k+1}^{r}\sigma_i^2}\)</span>.  Let’s plot this error as a function of <span class="math notranslate nohighlight">\(k\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">flip</span><span class="p">(</span><span class="n">s</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
<span class="n">errors</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">sr</span><span class="p">)</span>
<span class="n">errors</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">flip</span><span class="p">(</span><span class="n">errors</span><span class="p">)</span>
<span class="n">errors</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">errors</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">428</span><span class="p">),</span> <span class="n">errors</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Error of rank k approximation&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/eigenstuff_image-compression_13_0.png" src="../_images/eigenstuff_image-compression_13_0.png" />
</div>
</div>
<p>As we can see, the errors start large when <span class="math notranslate nohighlight">\(k\)</span> is small, but quickly get smaller as we increase the rank of our approximation.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./content"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="eigenstuff_SVD.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">7.5. </span>The Singular Value Decomposition</p>
        </div>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Michael W. Mahoney, N. Benjamin Erichson and Ryan Theisen<br/>
    
        &copy; Copyright 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>