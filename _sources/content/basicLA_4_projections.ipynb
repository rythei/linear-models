{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5eccf4c",
   "metadata": {},
   "source": [
    "# Projections\n",
    "\n",
    "In this section, we study special linear maps called _projections_. Formally, a projection $P(\\boldsymbol{x})$ is any linear map such that $P^2 = P$. In other words, a projection is simply a _idemptotent_ linear map.\n",
    "\n",
    "## Projections onto a vector\n",
    "\n",
    "We begin by considering perhaps the simplest possible projection: a projection onto a single vector. Intuitively, this is probably something you've already seen in high school math. The usual diagram given for this concept is below.\n",
    "\n",
    "<img src=\"img/projection_2d.png\" style=\"zoom:50%;\" />\n",
    "\n",
    "In the above figure, we are projecting a vector $\\boldsymbol{a}$ onto a vector $\\boldsymbol{b}$. The resulting projection is the vector $\\text{proj}_\\boldsymbol{b}(\\boldsymbol{a}) = \\boldsymbol{a}_1$, which is always parallel to $\\boldsymbol{b}$. The vector $\\boldsymbol{a}_2$ is the \"residual\" of the projection, which is  $\\boldsymbol{a}_2 = \\boldsymbol{a} - \\boldsymbol{a}_1 = \\boldsymbol{a} - \\text{proj}_\\boldsymbol{b}(\\boldsymbol{a})$. Note that visually from the diagram, we have that $\\boldsymbol{a} = \\boldsymbol{a}_1 + \\boldsymbol{a}_2$, which is of course obvious from the definitions of $\\boldsymbol{a}_1$ and $\\boldsymbol{a}_2$. We will see below that this diagram is in fact representing a special case of projection onto a vector -- namely, it represents an _orthogonal_ projection.\n",
    "\n",
    "### Orthogonal projections onto a vector\n",
    "\n",
    "There is a simple formula for the orthogonal projection of a vector $\\boldsymbol{a} \\in\\mathbb{R}^n$ onto another vector $\\boldsymbol{b}\\in \\mathbb{R}^n$. It is given by the following:\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "\\text{proj}_\\boldsymbol{b}(\\boldsymbol{a}) = \\frac{\\boldsymbol{b}^\\top \\boldsymbol{a}}{\\boldsymbol{b}^\\top \\boldsymbol{b}}\\boldsymbol{b}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "Notice that $\\frac{\\boldsymbol{b}^\\top \\boldsymbol{a}}{\\boldsymbol{b}^\\top \\boldsymbol{b}}$ is just a scalar (assuming $\\boldsymbol{b}\\neq 0$), and so $\\text{proj}_\\boldsymbol{b}(\\boldsymbol{a})$ is really just a rescaled version of the vector $\\boldsymbol{b}$. This means that for any vector $\\boldsymbol{a}$, $\\text{proj}_\\boldsymbol{b}(\\boldsymbol{a})$ is always parallel to $\\boldsymbol{b}$ -- this is why we say that it is a projection \"onto\" $\\boldsymbol{b}$. Why is this called an 'orthogonal' projection? This is because $\\text{proj}_\\boldsymbol{b}(\\boldsymbol{a})$ is always orthogonal to the \"residual\" $\\boldsymbol{a} - \\text{proj}_\\boldsymbol{b}(\\boldsymbol{a})$. Let's check that this is in fact true by computing $\\text{proj}_\\boldsymbol{b}(\\boldsymbol{a})^\\top (\\boldsymbol{a} - \\text{proj}_\\boldsymbol{b}(\\boldsymbol{a}))$.\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "\\text{proj}_\\boldsymbol{b}(\\boldsymbol{a})^\\top (\\boldsymbol{a} - \\text{proj}_\\boldsymbol{b}(\\boldsymbol{a})) = \\left(\\frac{\\boldsymbol{b}^\\top \\boldsymbol{a}}{\\boldsymbol{b}^\\top \\boldsymbol{b}}\\boldsymbol{b}\\right)^\\top\\left(\\boldsymbol{a} - \\frac{\\boldsymbol{b}^\\top \\boldsymbol{a}}{\\boldsymbol{b}^\\top \\boldsymbol{b}}\\boldsymbol{b}\\right) = \\frac{\\boldsymbol{b}^\\top \\boldsymbol{a}}{\\boldsymbol{b}^\\top \\boldsymbol{b}}\\left(\\boldsymbol{b}^\\top \\boldsymbol{a} - \\boldsymbol{b}^\\top \\boldsymbol{a}\\frac{\\boldsymbol{b}^\\top \\boldsymbol{b}}{\\boldsymbol{b}^\\top \\boldsymbol{b}}\\right) = \\frac{\\boldsymbol{b}^\\top \\boldsymbol{a}}{\\boldsymbol{b}^\\top \\boldsymbol{b}}(\\boldsymbol{b}^\\top \\boldsymbol{a} - \\boldsymbol{b}^\\top \\boldsymbol{a}) = 0\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "Hence the angle between $\\text{proj}_\\boldsymbol{b}(\\boldsymbol{a})$ and $\\boldsymbol{a} - \\text{proj}_\\boldsymbol{b}(\\boldsymbol{a})$ is always $90^\\circ$. You can also see this visually in the figure above.\n",
    "\n",
    "**Remark:** In the QR decomposition section, we saw the formula $\\frac{\\boldsymbol{b}^\\top \\boldsymbol{a}}{\\boldsymbol{b}^\\top \\boldsymbol{b}}\\boldsymbol{b}$ appear in the Gram--Schmidt orthogonalization procedure. This is no coincidence: there, we computed\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "\\boldsymbol{u}_j = \\boldsymbol{a}_j - \\sum_{i = 1}^{j-1}\\frac{\\boldsymbol{u}_i^\\top \\boldsymbol{a}_j}{\\boldsymbol{u}_i^\\top \\boldsymbol{u}_i}\\boldsymbol{u}_i = \\boldsymbol{a}_j - \\sum_{i=1}^{j-1}\\text{proj}_{\\boldsymbol{u}_i}(\\boldsymbol{a}_j)\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "That is, $\\boldsymbol{u}_j$ was the residual after projecting $\\boldsymbol{a}_j$ onto each of $\\boldsymbol{u}_1,\\dots, \\boldsymbol{u}_{j-1}$.\n",
    "\n",
    "As we mentioned previously, the projections we consider are _linear_ maps. We know that all linear maps can be represented as matrices. Let's see how we can represent $\\text{proj}_\\boldsymbol{b}(\\boldsymbol{a})$ as a matrix transformation. Using the associativity of inner and outer products, we can rearrange the formula for $\\text{proj}_\\boldsymbol{b}$ to see\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "\\text{proj}_\\boldsymbol{b}(\\boldsymbol{a}) = \\frac{\\boldsymbol{b}^\\top \\boldsymbol{a}}{\\boldsymbol{b}^\\top \\boldsymbol{b}}\\boldsymbol{b} = \\frac{1}{\\boldsymbol{b}^\\top \\boldsymbol{b}}\\boldsymbol{b}\\boldsymbol{b}^\\top \\boldsymbol{a} = \\frac{\\boldsymbol{b}\\boldsymbol{b}^\\top}{\\boldsymbol{b}^\\top \\boldsymbol{b}}\\boldsymbol{a} = \\boldsymbol{P_ba}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "where $\\boldsymbol{P_b} = \\frac{\\boldsymbol{bb}^\\top}{\\boldsymbol{b}^\\top \\boldsymbol{b}}$ is an $n\\times n$ matrix.\n",
    "\n",
    "As we mentioned before, projections should by definition satisfy the idempotence property $\\boldsymbol{P}^2 = \\boldsymbol{P}$. Let's check that this is true for $\\boldsymbol{P_b}$. We have\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "\\boldsymbol{P_b}^2 = \\frac{\\boldsymbol{bb}^\\top}{\\boldsymbol{b}^\\top \\boldsymbol{b}}\\frac{\\boldsymbol{bb}^\\top}{\\boldsymbol{b}^\\top \\boldsymbol{b}} = \\frac{1}{(\\boldsymbol{b}^\\top \\boldsymbol{b})^2}\\boldsymbol{bb}^\\top \\boldsymbol{bb}^\\top = \\frac{1}{(\\boldsymbol{b}^\\top \\boldsymbol{b})^2}\\boldsymbol{b}(\\boldsymbol{b}^\\top \\boldsymbol{b})\\boldsymbol{b}^\\top=\\frac{\\boldsymbol{b}^\\top \\boldsymbol{b}}{(\\boldsymbol{b}^\\top \\boldsymbol{b})^2}\\boldsymbol{bb}^\\top = \\frac{\\boldsymbol{bb}^\\top}{\\boldsymbol{b}^\\top \\boldsymbol{b}} = \\boldsymbol{P_b}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "Indeed, $\\boldsymbol{P_b}$ is idempotent.\n",
    "\n",
    "Let's look at some $2$-d examples of orthogonal projections. First, let's define a function `orthogonal_projection(b)` which takes in a vector $\\boldsymbol{b}$ and returns the projection matrix $\\boldsymbol{P_b} = \\frac{\\boldsymbol{bb}^\\top}{\\boldsymbol{b}^\\top \\boldsymbol{b}}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5220b223",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def orthogonal_projection(b):\n",
    "    return np.outer(b,b)/np.dot(b,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6b28c9",
   "metadata": {},
   "source": [
    " Now let's test this out with a vector that we'd like to project onto, say $\\boldsymbol{b}=\\begin{bmatrix}1\\\\2\\end{bmatrix}$. Let's visualize $\\boldsymbol{b}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ce14b43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "filenames": {
       "image/png": "/Volumes/GoogleDrive-112349428810515690974/My Drive/PhD/Teaching/Stat89A_Spring2022/linalg-for-datasci/_build/jupyter_execute/content/basicLA_4_projections_3_0.png"
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "b = np.array([1,2])\n",
    "origin = np.zeros(2)\n",
    "\n",
    "plt.quiver(*origin, *b, label='b', scale=1, units='xy', color='blue')\n",
    "plt.grid()\n",
    "\n",
    "plt.xlim(-1,1.5)\n",
    "plt.ylim(-1,2.5)\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0565d4f2",
   "metadata": {},
   "source": [
    "Next, let's compute the projection matrix $\\boldsymbol{P_b}$ using the function we defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95422c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pb = orthogonal_projection(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c11f26",
   "metadata": {},
   "source": [
    "Just to make sure we've done things correctly, let's verify that $\\boldsymbol{P_b}$ is idempotent, by checking that $\\boldsymbol{P_b}^2 = \\boldsymbol{P_b}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "679fc226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pb2 = np.dot(Pb, Pb)\n",
    "np.allclose(Pb2, Pb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bd9758",
   "metadata": {},
   "source": [
    "Indeed it is. Now, let's try projecting a vector, say $\\boldsymbol{a} = \\begin{bmatrix}1\\\\ 1\\end{bmatrix}$, onto $\\boldsymbol{b}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65b5a961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "filenames": {
       "image/png": "/Volumes/GoogleDrive-112349428810515690974/My Drive/PhD/Teaching/Stat89A_Spring2022/linalg-for-datasci/_build/jupyter_execute/content/basicLA_4_projections_9_0.png"
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = np.array([1, 1])\n",
    "proj_b_a = np.dot(Pb, a) # compute the projection of a onto b\n",
    "residual = a - proj_b_a\n",
    "\n",
    "plt.quiver(*origin, *b, label='b', scale=1, units='xy', color='blue')\n",
    "plt.quiver(*origin, *a, label='a', scale=1, units='xy', color='green')\n",
    "plt.quiver(*origin, *proj_b_a, label='proj_b(a)', scale=1, units='xy', color='red')\n",
    "plt.quiver(*proj_b_a, *residual, label='a - proj_b(a)', scale=1, units='xy', color='orange')\n",
    "plt.grid()\n",
    "\n",
    "plt.xlim(-1,1.5)\n",
    "plt.ylim(-1,2.5)\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9dd567",
   "metadata": {},
   "source": [
    "This plot now largely replicates the figure we saw earlier: we see that 1) the projection of $\\boldsymbol{a}$ onto $\\boldsymbol{b}$ is a vector (in red) which is parallel to $\\boldsymbol{b}$ and 2) the residual $\\boldsymbol{a} - \\text{proj}_\\boldsymbol{b}(\\boldsymbol{a})$ is at a $90^\\circ$ angle from $\\text{proj}_\\boldsymbol{b}(\\boldsymbol{a})$.\n",
    "\n",
    "### Oblique projections onto a vector\n",
    "\n",
    "While orthogonal projections are commonly used, and in many ways special, they are not the only way we can project onto a vector. Indeed, we can define a projection of a vector $\\boldsymbol{a}$ onto another vector $\\boldsymbol{b}$ not just along the direction orthogonal to $\\boldsymbol{b}$, but along any arbitrary direction. The projection of a vector $\\boldsymbol{a}$ onto the vector $\\boldsymbol{b}$ _along the direction perpendicular to $\\boldsymbol{c}$_ is given by the following:\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "\\text{proj}_{\\boldsymbol{b},\\boldsymbol{c}}(\\boldsymbol{a}) = \\frac{\\boldsymbol{c}^\\top \\boldsymbol{a}}{\\boldsymbol{b}^\\top \\boldsymbol{c}}\\boldsymbol{b}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "Again, $\\frac{\\boldsymbol{c}^\\top \\boldsymbol{a}}{\\boldsymbol{b}^\\top \\boldsymbol{c}}$ is just a scalar, so this vector is again just a rescaled version of $\\boldsymbol{b}$. We can also rearrange this formula to write it as a linear function in terms of a matrix\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "\\boldsymbol{P}_{\\boldsymbol{b},\\boldsymbol{c}} = \\frac{\\boldsymbol{bc}^\\top}{\\boldsymbol{b}^\\top \\boldsymbol{c}}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "So that $\\text{proj}_{\\boldsymbol{b},\\boldsymbol{c}}(\\boldsymbol{a}) = \\boldsymbol{P}_{\\boldsymbol{b},\\boldsymbol{c}}\\boldsymbol{a}$. Let's verify that $\\boldsymbol{P}_{\\boldsymbol{b},\\boldsymbol{c}}$ also satisfies the idempotence property $\\boldsymbol{P}^2 = \\boldsymbol{P}$.\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "\\boldsymbol{P}_{\\boldsymbol{b},\\boldsymbol{c}}^2 = \\frac{\\boldsymbol{bc}^\\top}{\\boldsymbol{b}^\\top \\boldsymbol{c}}\\frac{\\boldsymbol{bc}^\\top}{\\boldsymbol{b^\\top c}} = \\frac{1}{(\\boldsymbol{b^\\top c})^2}\\boldsymbol{bc}^\\top \\boldsymbol{bc}^\\top = \\frac{1}{(\\boldsymbol{b^\\top c})^2}\\boldsymbol{b}(\\boldsymbol{c^\\top b})\\boldsymbol{c}^\\top = \\frac{\\boldsymbol{c^\\top b}}{(\\boldsymbol{b^\\top c})^2}\\boldsymbol{bc}^\\top = \\frac{\\boldsymbol{bc}^\\top}{\\boldsymbol{b^\\top c}} = \\boldsymbol{P}_{\\boldsymbol{b},\\boldsymbol{c}}.\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "Indeed, $\\boldsymbol{P}_{\\boldsymbol{b},\\boldsymbol{c}}$ is also a valid projection. So then what is the difference between $\\boldsymbol{P}_{\\boldsymbol{b},\\boldsymbol{c}}$ and the orthogonal projection $\\boldsymbol{P}_\\boldsymbol{b}$ that we saw before? The difference lies in the fact that the _residuals_ are no longer orthogonal; that is, the angle between $\\text{proj}_{\\boldsymbol{b},\\boldsymbol{c}}(\\boldsymbol{a})$ and $\\boldsymbol{a} - \\text{proj}_{\\boldsymbol{b},\\boldsymbol{c}}(\\boldsymbol{a})$ is no longer $90^\\circ$. Let's check that this.\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "\\text{proj}_{\\boldsymbol{b},\\boldsymbol{c}}(\\boldsymbol{a})^\\top (\\boldsymbol{a} - \\text{proj}_{\\boldsymbol{b},\\boldsymbol{c}}(\\boldsymbol{a})) = \\left(\\frac{\\boldsymbol{c^\\top a}}{\\boldsymbol{b^\\top c}}\\boldsymbol{b}\\right)^\\top\\left(\\boldsymbol{a} - \\frac{\\boldsymbol{c^\\top a}}{\\boldsymbol{b^\\top c}}\\boldsymbol{b}\\right) = \\frac{\\boldsymbol{c^\\top a}}{\\boldsymbol{b^\\top c}}\\left(\\boldsymbol{b^\\top a} - \\frac{\\boldsymbol{c^\\top a}}{\\boldsymbol{b^\\top c}}\\boldsymbol{b^\\top b}\\right)\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "This quantity will only be zero for any $\\boldsymbol{a}$ if  $\\boldsymbol{b^\\top a} - \\frac{\\boldsymbol{c^\\top a}}{\\boldsymbol{b^\\top c}}\\boldsymbol{b^\\top b} = 0$. This happens when $\\boldsymbol{b}=\\boldsymbol{c}$, in which case we return to get the orthogonal projection back, but for any other $\\boldsymbol{c}$ we will not have that the residuals are orthogonal to $\\text{proj}_{\\boldsymbol{b},\\boldsymbol{c}}(\\boldsymbol{a})$. Therefore, projections of this form are called _oblique_ projections. Let's see an example in $\\mathbb{R}^2$.\n",
    "\n",
    "Let's write a function to compute $\\text{proj}_{b,c}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "585c5104",
   "metadata": {},
   "outputs": [],
   "source": [
    "def oblique_projection(b, c):\n",
    "    return np.outer(b,c)/np.dot(b,c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e317ffcd",
   "metadata": {},
   "source": [
    "Let's again project the vector $\\boldsymbol{b}=\\begin{bmatrix}1\\\\1\\end{bmatrix}$ onto the vector $\\boldsymbol{b}=\\begin{bmatrix}1\\\\2\\end{bmatrix}$, but this time along the direction $\\boldsymbol{c} =\\begin{bmatrix}1\\\\1/4\\end{bmatrix}$. First, we'll compute $\\boldsymbol{P}_{\\boldsymbol{b},\\boldsymbol{c}}$ using our oblique projection function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "337902b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.array([1,0.25])\n",
    "\n",
    "Pbc = oblique_projection(b,c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9614f38",
   "metadata": {},
   "source": [
    "Let's verify that $\\boldsymbol{P}_{\\boldsymbol{b},\\boldsymbol{c}}^2 = \\boldsymbol{P}_{\\boldsymbol{b},\\boldsymbol{c}}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb6d4305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pbc2 = np.dot(Pbc, Pbc)\n",
    "\n",
    "np.allclose(Pbc2, Pbc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3138203e",
   "metadata": {},
   "source": [
    "So $\\boldsymbol{P}_{\\boldsymbol{b},\\boldsymbol{c}}$ is indeed idempotent. Now let's visualize $\\boldsymbol{a},\\boldsymbol{b}, \\text{proj}_{\\boldsymbol{b},\\boldsymbol{c}}(\\boldsymbol{a})$ and $\\boldsymbol{a}-\\text{proj}_{\\boldsymbol{b},\\boldsymbol{c}}(\\boldsymbol{a})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a16999c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "filenames": {
       "image/png": "/Volumes/GoogleDrive-112349428810515690974/My Drive/PhD/Teaching/Stat89A_Spring2022/linalg-for-datasci/_build/jupyter_execute/content/basicLA_4_projections_17_0.png"
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "proj_bc_a = np.dot(Pbc, a) # compute the projection of a onto b\n",
    "residual = a - proj_bc_a\n",
    "\n",
    "plt.quiver(*origin, *b, label='b', scale=1, units='xy', color='blue')\n",
    "plt.quiver(*origin, *a, label='a', scale=1, units='xy', color='green')\n",
    "plt.quiver(*origin, *proj_bc_a, label='proj_bc(a)', scale=1, units='xy', color='red')\n",
    "plt.quiver(*proj_bc_a, *residual, label='a - proj_bc(a)', scale=1, units='xy', color='orange')\n",
    "plt.grid()\n",
    "\n",
    "plt.xlim(-1,1.5)\n",
    "plt.ylim(-1,2.5)\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1041017",
   "metadata": {},
   "source": [
    "In this plot, we see that $\\text{proj}_{\\boldsymbol{b},\\boldsymbol{c}}(\\boldsymbol{a})$ is indeed parallel to $\\boldsymbol{b}$, but it is not at a $90^\\circ$ angle from the residual $\\boldsymbol{a}-\\text{proj}_{\\boldsymbol{b},\\boldsymbol{c}}(\\boldsymbol{a})$. Let's actually compute the angle between $\\text{proj}_{\\boldsymbol{b},\\boldsymbol{c}}(\\boldsymbol{a})$ and $\\boldsymbol{a}-\\text{proj}_{\\boldsymbol{b},\\boldsymbol{c}}(\\boldsymbol{a})$ using techniques that we learned earlier in the chapter (recall that the angle between vectors $\\boldsymbol{x}$ and $\\boldsymbol{y}$ is $\\arccos\\left(\\frac{\\boldsymbol{x^\\top y}}{\\|\\boldsymbol{x}\\|_2\\|\\boldsymbol{y}\\|_2}\\right)$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "447167d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4329663814621227"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = np.dot(proj_bc_a, residual)\n",
    "residual_norm = np.linalg.norm(residual)\n",
    "proj_bc_a_norm = np.linalg.norm(proj_bc_a)\n",
    "\n",
    "angle = np.arccos(temp/(residual_norm*proj_bc_a_norm))\n",
    "angle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b573bd9",
   "metadata": {},
   "source": [
    "Indeed, we get that the angle between $\\text{proj}_{\\boldsymbol{b},\\boldsymbol{c}}(\\boldsymbol{a})$ and $\\boldsymbol{a}-\\text{proj}_{\\boldsymbol{b},\\boldsymbol{c}}(\\boldsymbol{a})$ is approximately $2.43$ radians, which is roughly $140^\\circ$.\n",
    "\n",
    "## Projections onto a subspace\n",
    "\n",
    "In the above sections, we phrased projections as projecting a vector $\\boldsymbol{a}$ onto another _vector_ $\\boldsymbol{b}$. In reality, what we computed was actually the projection of $\\boldsymbol{a}$ onto the _subspace_ $V = \\text{span}(\\boldsymbol{b})$.\n",
    "\n",
    "It turns out that there's nothing special about projecting onto a $1$-dimensional subspace: we can define orthogonal and oblique projections onto any subspace, as we will see below.\n",
    "\n",
    "### Orthogonal projections onto a subspace\n",
    "\n",
    "Let's begin with the concept of an orthogonal projection onto a subspace. Let $V$ be a subspace of $\\mathbb{R}^n$, spanned by vectors $\\boldsymbol{a}_1,\\dots, \\boldsymbol{a}_k$. Let's let $\\boldsymbol{A}$ be the matrix whose columns are $\\boldsymbol{a}_1,\\dots, \\boldsymbol{a}_k$, i.e.\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "\\boldsymbol{A} = \\begin{bmatrix} | & | && |\\\\ \\boldsymbol{a}_1 & \\boldsymbol{a}_2 & \\cdots & \\boldsymbol{a}_k \\\\ | & | & & |\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "Let's see how we can derive the orthogonal projection onto $V$, which is just the column space of $\\boldsymbol{A}$. Consider projecting a vector $\\boldsymbol{b}$ onto $V$ -- call this projection $\\hat{\\boldsymbol{b}} = \\text{proj}_V(\\boldsymbol{b})$. Since $\\hat{\\boldsymbol{b}}$ should belong to the column space of $\\boldsymbol{A}$, it should be of the form $\\hat{\\boldsymbol{b}} = \\boldsymbol{A}\\hat{\\boldsymbol{x}}$ for some vector $\\hat{\\boldsymbol{x}}.$ For this projection to be orthogonal, we want that $\\boldsymbol{b}- \\hat{\\boldsymbol{b}} =\\boldsymbol{b}-\\boldsymbol{A}\\hat{\\boldsymbol{x}}$ to be orthogonal to all the columns of $\\boldsymbol{A}$. Earlier in the chapter, we saw that this means that $\\boldsymbol{A}^\\top(\\boldsymbol{b} - \\boldsymbol{A}\\hat{\\boldsymbol{x}}) = 0$. Then\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "\\boldsymbol{A^\\top}(\\boldsymbol{b}-\\boldsymbol{A} \\hat{\\boldsymbol{x}}) = 0 \\iff \\boldsymbol{A^\\top b} = \\boldsymbol{A^\\top A}\\hat{\\boldsymbol{x}} \\iff \\hat{\\boldsymbol{x}} = (\\boldsymbol{A^\\top A})^{-1}\\boldsymbol{A^\\top b}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "Since $\\hat{\\boldsymbol{b}} = \\boldsymbol{A}\\hat{\\boldsymbol{x}}$, we get\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "\\text{proj}_V(\\boldsymbol{b}) = \\hat{\\boldsymbol{b}} = \\boldsymbol{A}\\hat{\\boldsymbol{x}} = \\boldsymbol{A}(\\boldsymbol{A^\\top A})^{-1}\\boldsymbol{A}^\\top \\boldsymbol{b}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "This immediately gives us a formula for the projection matrix $\\boldsymbol{P}_V$:\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "\\boldsymbol{P}_V = \\boldsymbol{A}(\\boldsymbol{A^\\top A})^{-1}\\boldsymbol{A}^\\top\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "This is an important formula that we will see again later in the semester. Let's check that $\\boldsymbol{P}_V$ satisfies the idempotence condition $\\boldsymbol{P}_V^2 = \\boldsymbol{P}_V$. We have\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "\\boldsymbol{P}_V^2 = \\boldsymbol{A}(\\boldsymbol{A^\\top A})^{-1}\\underbrace{\\boldsymbol{A^\\top A}(\\boldsymbol{A^\\top A})^{-1}}_{\\boldsymbol{I}}\\boldsymbol{A}^\\top = \\boldsymbol{A}(\\boldsymbol{A^\\top A})^{-1}\\boldsymbol{A}^\\top = \\boldsymbol{P}_V\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "Indeed it does. Now let's look at an example numerically. Consider the matrix\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "\\boldsymbol{A} =\\begin{bmatrix} \\boldsymbol{a}_1 & \\boldsymbol{a}_2\\end{bmatrix} = \\begin{bmatrix} 1 & 0\\\\ 1 & 1 \\\\ 0 &1\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "Where here $\\boldsymbol{a}_1 = \\begin{bmatrix}1\\\\1\\\\0\\end{bmatrix}$ and $\\boldsymbol{a}_2 = \\begin{bmatrix}0\\\\ 1\\\\1\\end{bmatrix}$. Let's compute the projection onto $V = \\text{span}(\\boldsymbol{a}_1,\\boldsymbol{a}_2)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a2b1c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1,0], [1,1], [0,1]])\n",
    "ATA_inv = np.linalg.inv(np.dot(A.T, A)) # compute (A^TA)^{-1}\n",
    "PV = np.dot(A, np.dot(ATA_inv, A.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9316be",
   "metadata": {},
   "source": [
    "Let's verify that this worked, by checking numerically that $P_V^2 = P_V$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a73e7930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PV2 = np.dot(PV, PV)\n",
    "np.allclose(PV2, PV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8308147",
   "metadata": {},
   "source": [
    "Indeed it does.\n",
    "\n",
    "Let's now verify that this projection is orthogonal to the column space of $\\boldsymbol{A}$, by computing $\\boldsymbol{A}^\\top(\\boldsymbol{b} - \\text{proj}_V(\\boldsymbol{b}))$. For this example, we'll use the vector $\\boldsymbol{b} = \\begin{bmatrix}1\\\\ 2\\\\ 3\\end{bmatrix}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a39b9827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.array([1,2,3])\n",
    "\n",
    "proj_V_b = np.dot(PV, b)\n",
    "residual = b - proj_V_b\n",
    "\n",
    "np.dot(A.T, residual).round(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409694cd",
   "metadata": {},
   "source": [
    "Indeed, we get the zeros vector, and so $\\boldsymbol{b}-\\text{proj}_V(\\boldsymbol{b})$ is orthogonal to the columns of $\\boldsymbol{A}$.\n",
    "\n",
    "#### Relationship with the QR decomposition\n",
    "\n",
    "In the previous workbook, we saw that we can write any matrix $\\boldsymbol{A}$ as $\\boldsymbol{A} = \\boldsymbol{QR}$ where $\\boldsymbol{Q}$ is an orthogonal matrix and $\\boldsymbol{R}$ is upper triangular. Here, we'll see that we can write the projection onto the column space conveniently in terms of $\\boldsymbol{Q}$. Let's plug in $\\boldsymbol{A} = \\boldsymbol{QR}$ into our formula for $\\boldsymbol{P}_V$ (and recall that $\\boldsymbol{Q^\\top Q} = \\boldsymbol{I}$).\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "\\boldsymbol{P}_V = \\boldsymbol{QR}((\\boldsymbol{QR})^\\top \\boldsymbol{QR})^{-1}(\\boldsymbol{QR})^\\top = \\boldsymbol{QR}(\\boldsymbol{R}^\\top \\underbrace{\\boldsymbol{Q^\\top Q}}_{\\boldsymbol{I}} \\boldsymbol{R})^{-1}\\boldsymbol{R^\\top Q}^\\top = \\boldsymbol{QR}(\\boldsymbol{R^\\top R})^{-1}\\boldsymbol{R^\\top Q}^\\top = \\boldsymbol{Q}\\underbrace{\\boldsymbol{RR}^{-1}}_{\\boldsymbol{I}}\\underbrace{(\\boldsymbol{R}^\\top)^{-1}\\boldsymbol{R}^\\top}_{\\boldsymbol{I}} \\boldsymbol{Q}^\\top = \\boldsymbol{QQ}^\\top\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "Therefore, if we have the QR decomposition of $\\boldsymbol{A}$, the projection onto the column space of $\\boldsymbol{A}$ can be easily computed with $\\boldsymbol{QQ}^\\top$. This is convenient as it doesn't require taking any matrix inverses, which can be difficult to work with numerically.\n",
    "\n",
    "**Remark:** Recall that we always have that $\\boldsymbol{Q^\\top Q} = \\boldsymbol{I}$ for an orthogonal matrix $\\boldsymbol{Q}$. Here we see clearly that $\\boldsymbol{QQ}^\\top$ is emphatically _not_ equal to the identity in general.\n",
    "\n",
    "Let's use this method to compute the projection $\\boldsymbol{P}_V$ using the same matrix $\\boldsymbol{A}$ as above. Here we use the built-in numpy function for the QR decomposition, but we could just as well have used the QR function that we wrote ourselves in the previous workbook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da54c29b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q, R = np.linalg.qr(A)\n",
    "QQT = np.dot(Q, Q.T)\n",
    "np.allclose(QQT, PV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04d60bb",
   "metadata": {},
   "source": [
    "Indeed, the two approaches give us the same answer.\n",
    "\n",
    "The last point we make before moving on is that there are _many_ possible matrices $\\boldsymbol{A}$ whose columns span a given subspace $V$. For example, the matrix\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "\\boldsymbol{B} = \\begin{bmatrix} -2 & 0\\\\ -2 & 4 \\\\ 0 &4\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "has the same column space as $\\boldsymbol{A}$. Let's check that computing the projection using this matrix gives us the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26f39a9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = np.array([[-2, 0], [-2, 4], [0, 4]])\n",
    "\n",
    "Q2, R2 = np.linalg.qr(B)\n",
    "QQT2 = np.dot(Q2, Q2.T)\n",
    "np.allclose(QQT, QQT2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf483fb",
   "metadata": {},
   "source": [
    "Indeed, the projection onto $V$ is the same no matter which spanning vectors we use.\n",
    "\n",
    "### Oblique projections onto a subspace\n",
    "\n",
    "Like in the case of projecting onto vectors, we can also have _oblique_ projections onto the column space of a matrix $\\boldsymbol{A}$, which is the subspace $V$. Let $\\boldsymbol{C}$ be any $n\\times k$ matrix such that $\\boldsymbol{C^\\top A}$ is invertible. Then the matrix\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "P_{V,\\boldsymbol{C}} = \\boldsymbol{A}(\\boldsymbol{C^\\top A})^{-1}\\boldsymbol{C}^\\top\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "is always a projection onto $V$. It will of course reduce to the orthogonal projection when $\\boldsymbol{C} = \\boldsymbol{A}$, in which case we obtain the same  formula that we had before. To check that it is indeed a projection, we need to verify that $\\boldsymbol{P}_{V,\\boldsymbol{C}}^2 = \\boldsymbol{P}_{V,\\boldsymbol{C}}$. We calculate\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "\\boldsymbol{P}_{V,\\boldsymbol{C}}^2 = \\boldsymbol{A}(\\boldsymbol{C^\\top A})^{-1}\\underbrace{\\boldsymbol{C^\\top A}(\\boldsymbol{C^\\top A})^{-1}}_{\\boldsymbol{I}}\\boldsymbol{C}^\\top = \\boldsymbol{A}(\\boldsymbol{C^\\top A})^{-1}\\boldsymbol{C}^\\top = \\boldsymbol{P}_{V,\\boldsymbol{C}}\n",
    "$$\n",
    "\n",
    "\n",
    "So $\\boldsymbol{P}_{V,\\boldsymbol{C}}$ is in fact a valid projection. Let's first look at an example with the matrix $\\boldsymbol{A} = \\begin{bmatrix} 1 & 0\\\\ 1 & 1 \\\\ 0 &1\\end{bmatrix}$ that we used above. There are many valid examples of matrices $\\boldsymbol{C}$ that we can use to define an oblique projection $\\boldsymbol{P}_{V,\\boldsymbol{C}}$; indeed, for most matrices $\\boldsymbol{C}$ we will have that $\\boldsymbol{C^\\top A}$ is invertible. Let's try choosing $\\boldsymbol{C}$ to be a random matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5dc1776a",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 2\n",
    "n = 3\n",
    "\n",
    "C = np.random.normal(size = (n,k))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122e3318",
   "metadata": {},
   "source": [
    "Let's check that $\\boldsymbol{C^\\top A}$ is invertible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85e97f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CTA_inv = np.linalg.inv(np.dot(C.T, A))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4ec1e7",
   "metadata": {},
   "source": [
    "Indeed, computing the inverse works without error.\n",
    "\n",
    "Now, let's use this to compute $\\boldsymbol{P}_{V,\\boldsymbol{C}}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58885aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "PVC = np.dot(A, np.dot(CTA_inv, C.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a31c3f",
   "metadata": {},
   "source": [
    "We can check numerically that $\\boldsymbol{P}_{V,\\boldsymbol{C}}^2 = \\boldsymbol{P}_{V,\\boldsymbol{C}}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98b73d1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PVC2 = np.dot(PVC, PVC)\n",
    "np.allclose(PVC2, PVC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470b86a2",
   "metadata": {},
   "source": [
    "So $\\boldsymbol{P}_{V,\\boldsymbol{C}}$ is in fact idempotent, and thus a valid projection. However, it is not orthogonal; we can check this by computing $\\boldsymbol{A}^\\top (\\boldsymbol{b} - \\boldsymbol{P}_{V,\\boldsymbol{C}}\\boldsymbol{b})$, and verifying that it is not equal to zero (as it was in the orthogonal case). Let's do this for the same vector $\\boldsymbol{b} = \\begin{bmatrix}1\\\\ 2\\\\ 3\\end{bmatrix}$ that we used before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f5a48170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.06215663,  5.40986263])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proj_VC_b = np.dot(PVC, b)\n",
    "residuals = b - proj_VC_b\n",
    "np.dot(A.T, residuals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca5109d",
   "metadata": {},
   "source": [
    " Our answer is clearly not zero, and so the projection $\\boldsymbol{P}_{V,\\boldsymbol{C}}$ is _not_ an orthogonal projection, but rather an _oblique_ projection.\n",
    "\n",
    "## Projecting onto the orthogonal complement of a subspace\n",
    "\n",
    "The last type of projection we will discuss is the projection onto the _orthogonal complement_ of a subspace $V\\subseteq \\mathbb{R}^n$. The orthogonal complement is the subspace $V^\\perp$ which is defined as follows:\n",
    "\n",
    "\n",
    "$$\n",
    "V^\\perp = \\{\\boldsymbol{w}\\in \\mathbb{R}^n : \\boldsymbol{w^\\top v} = 0\\text{ for all } \\boldsymbol{v}\\in V\\}\n",
    "$$\n",
    "\n",
    "\n",
    "That is, the orthogonal complement of $V$ is the set of all vectors which are orthogonal to all vectors in $V$. It turns out that the projection onto the orthogonal complement is easy to find given the orthogonal projection onto $V$. If $\\boldsymbol{P}_V$ is the orthogonal projection onto $V$, then the orthogonal projection onto $V^\\perp$ is just\n",
    "\n",
    "\n",
    "$$\n",
    "\\boldsymbol{P}_{V^\\perp} = \\boldsymbol{I} - \\boldsymbol{P}_V\n",
    "$$\n",
    "\n",
    "\n",
    "Given $\\boldsymbol{P}_V = \\boldsymbol{A}(\\boldsymbol{A^\\top A})^{-1}\\boldsymbol{A}^\\top$ or $\\boldsymbol{P}_V = \\boldsymbol{QQ}^\\top$ (where $\\boldsymbol{Q}$ comes from the QR factorization of $\\boldsymbol{A}$), this means $\\boldsymbol{P}_{V^\\perp} = \\boldsymbol{I}- \\boldsymbol{A}(\\boldsymbol{A^\\top A})^{-1}\\boldsymbol{A}^\\top$ or $\\boldsymbol{P}_{V^\\perp} = \\boldsymbol{I}- \\boldsymbol{QQ}^\\top$. Since the range of $\\boldsymbol{P}_V$ is $V$, and the range of $\\boldsymbol{P}_{V^\\perp}$ is $V^\\perp$, we should always have that $\\boldsymbol{P}_V \\boldsymbol{x}$ is orthogonal to $\\boldsymbol{P}_{V^\\perp}\\boldsymbol{y}$ for any vectors $\\boldsymbol{x}$ and $\\boldsymbol{y}$. Let's check that this is in fact true. We have\n",
    "\n",
    "\n",
    "$$\n",
    "(\\boldsymbol{P}_{V^\\perp}\\boldsymbol{y})^\\top \\boldsymbol{P}_{V}\\boldsymbol{x} = \\boldsymbol{y}^\\top \\boldsymbol{P}_{V^\\perp}\\boldsymbol{P}_V\\boldsymbol{x} = \\boldsymbol{y}^\\top (\\boldsymbol{I}-\\boldsymbol{P}_V)\\boldsymbol{P}_V\\boldsymbol{x} = \\boldsymbol{y}^\\top \\boldsymbol{P}_V\\boldsymbol{x} - \\boldsymbol{y}^\\top \\boldsymbol{P}_V^2\\boldsymbol{x} = \\boldsymbol{y}^\\top \\boldsymbol{P}_V\\boldsymbol{x} - \\boldsymbol{y}^\\top \\boldsymbol{P}_V \\boldsymbol{x} = 0\n",
    "$$\n",
    "\n",
    "\n",
    "where we used the fact that $\\boldsymbol{P}_V$ is a projection, so $\\boldsymbol{P}_V^2 = \\boldsymbol{P}_V$."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.12,
    "jupytext_version": "1.9.1"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "source_map": [
   12,
   88,
   93,
   97,
   111,
   115,
   117,
   121,
   124,
   128,
   144,
   194,
   197,
   201,
   205,
   209,
   213,
   217,
   232,
   236,
   243,
   319,
   323,
   327,
   330,
   336,
   343,
   365,
   369,
   385,
   391,
   418,
   423,
   427,
   429,
   435,
   437,
   441,
   444,
   448,
   452
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}